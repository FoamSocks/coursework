{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: LD_LIBRARY_PATH='/home/alexander.huang/.conda/envs/tf/lib/:/home/alexander.huang/.local/lib/python3.7/site-packages/tensorrt'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "tfd = tfp.distributions\n",
    "%env LD_LIBRARY_PATH='/home/alexander.huang/.conda/envs/tf/lib/:/home/alexander.huang/.local/lib/python3.7/site-packages/tensorrt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method DataFrame.info of      0   1        2        3        4        5        6        7        8   \\\n",
      "0     1   0  0.99539 -0.05889  0.85243  0.02306  0.83398 -0.37708  1.00000   \n",
      "1     1   0  1.00000 -0.18829  0.93035 -0.36156 -0.10868 -0.93597  1.00000   \n",
      "2     1   0  1.00000 -0.03365  1.00000  0.00485  1.00000 -0.12062  0.88965   \n",
      "3     1   0  1.00000 -0.45161  1.00000  1.00000  0.71216 -1.00000  0.00000   \n",
      "4     1   0  1.00000 -0.02401  0.94140  0.06531  0.92106 -0.23255  0.77152   \n",
      "..   ..  ..      ...      ...      ...      ...      ...      ...      ...   \n",
      "346   1   0  0.83508  0.08298  0.73739 -0.14706  0.84349 -0.05567  0.90441   \n",
      "347   1   0  0.95113  0.00419  0.95183 -0.02723  0.93438 -0.01920  0.94590   \n",
      "348   1   0  0.94701 -0.00034  0.93207 -0.03227  0.95177 -0.03431  0.95584   \n",
      "349   1   0  0.90608 -0.01657  0.98122 -0.01989  0.95691 -0.03646  0.85746   \n",
      "350   1   0  0.84710  0.13533  0.73638 -0.06151  0.87873  0.08260  0.88928   \n",
      "\n",
      "          9   ...       25       26       27       28       29       30  \\\n",
      "0    0.03760  ... -0.51171  0.41078 -0.46168  0.21266 -0.34090  0.42267   \n",
      "1   -0.04549  ... -0.26569 -0.20468 -0.18401 -0.19040 -0.11593 -0.16626   \n",
      "2    0.01198  ... -0.40220  0.58984 -0.22145  0.43100 -0.17365  0.60436   \n",
      "3    0.00000  ...  0.90695  0.51613  1.00000  1.00000 -0.20099  0.25682   \n",
      "4   -0.16399  ... -0.65158  0.13290 -0.53206  0.02431 -0.62197 -0.05707   \n",
      "..       ...  ...      ...      ...      ...      ...      ...      ...   \n",
      "346 -0.04622  ... -0.04202  0.83479  0.00123  1.00000  0.12815  0.86660   \n",
      "347  0.01606  ...  0.01361  0.93522  0.04925  0.93159  0.08168  0.94066   \n",
      "348  0.02446  ...  0.03193  0.92489  0.02542  0.92120  0.02242  0.92459   \n",
      "349  0.00110  ... -0.02099  0.89147 -0.07760  0.82983 -0.17238  0.96022   \n",
      "350 -0.09139  ... -0.15114  0.81147 -0.04822  0.78207 -0.00703  0.75747   \n",
      "\n",
      "          31       32       33  34  \n",
      "0   -0.54487  0.18641 -0.45300   g  \n",
      "1   -0.06288 -0.13738 -0.02447   b  \n",
      "2   -0.24180  0.56045 -0.38238   g  \n",
      "3    1.00000 -0.32382  1.00000   b  \n",
      "4   -0.59573 -0.04608 -0.65697   g  \n",
      "..       ...      ...      ...  ..  \n",
      "346 -0.10714  0.90546 -0.04307   g  \n",
      "347 -0.00035  0.91483  0.04712   g  \n",
      "348  0.00442  0.92697 -0.00577   g  \n",
      "349 -0.03757  0.87403 -0.16243   g  \n",
      "350 -0.06678  0.85764 -0.06151   g  \n",
      "\n",
      "[351 rows x 35 columns]>\n"
     ]
    }
   ],
   "source": [
    "ion_data = pd.read_csv('../data/ionosphere.csv', header=None)\n",
    "print(ion_data.info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "g class: 0\n",
      "b class: 1\n",
      "[0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0\n",
      " 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1\n",
      " 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 0 1 0 1 0 1 0 1 0 1 0 1 0 1\n",
      " 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0\n",
      " 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1\n",
      " 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0\n",
      " 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "def ordinal_encoder(category):\n",
    "    dict = {'g': 0, 'b': 1}\n",
    "    return dict[category]\n",
    "\n",
    "print('g class:', ordinal_encoder('g'))\n",
    "print('b class:', ordinal_encoder('b'))\n",
    "ion_data[34] = ion_data[34].apply(ordinal_encoder)\n",
    "print(ion_data[34].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(351, 33)\n",
      "(351, 1)\n"
     ]
    }
   ],
   "source": [
    "# split x and y\n",
    "x = ion_data.iloc[:,0:33].to_numpy()\n",
    "y = ion_data.iloc[:,34].to_numpy().reshape(-1,1)\n",
    "\n",
    "# Scaling\n",
    "scaler = StandardScaler()\n",
    "x = scaler.fit_transform(x)\n",
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_examples = y.shape[0]\n",
    "expectNLL = lambda y, rv_y: -rv_y.log_prob(y)/n_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2015 The TensorFlow Authors. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "# ==============================================================================\n",
    "\"\"\"Contains the MCDropout layer.\"\"\"\n",
    "\n",
    "\n",
    "import tensorflow.compat.v2 as tf\n",
    "\n",
    "from keras import backend\n",
    "from keras.engine import base_layer\n",
    "from keras.utils import control_flow_util\n",
    "\n",
    "# isort: off\n",
    "from tensorflow.python.util.tf_export import keras_export\n",
    "\n",
    "\n",
    "#@keras_export(\"keras.layers.Dropout\")\n",
    "class MCDropout(base_layer.BaseRandomLayer):\n",
    "    \"\"\"Applies MCDropout to the input.\n",
    "\n",
    "    The MCDropout layer randomly sets input units to 0 with a frequency of `rate`\n",
    "    at each step, which helps prevent overfitting.\n",
    "    Inputs not set to 0 are scaled up by 1/(1 - rate) such that the sum over\n",
    "    all inputs is unchanged.\n",
    "\n",
    "    >>> tf.random.set_seed(0)\n",
    "    >>> layer = tf.keras.layers.Dropout(.2, input_shape=(2,))\n",
    "    >>> data = np.arange(10).reshape(5, 2).astype(np.float32)\n",
    "    >>> print(data)\n",
    "    [[0. 1.]\n",
    "     [2. 3.]\n",
    "     [4. 5.]\n",
    "     [6. 7.]\n",
    "     [8. 9.]]\n",
    "    >>> outputs = layer(data)\n",
    "    >>> print(outputs)\n",
    "    tf.Tensor(\n",
    "    [[ 0.    1.25]\n",
    "     [ 2.5   3.75]\n",
    "     [ 5.    6.25]\n",
    "     [ 7.5   8.75]\n",
    "     [10.    0.  ]], shape=(5, 2), dtype=float32)\n",
    "\n",
    "    Args:\n",
    "      rate: Float between 0 and 1. Fraction of the input units to drop.\n",
    "      noise_shape: 1D integer tensor representing the shape of the\n",
    "        binary dropout mask that will be multiplied with the input.\n",
    "        For instance, if your inputs have shape\n",
    "        `(batch_size, timesteps, features)` and\n",
    "        you want the dropout mask to be the same for all timesteps,\n",
    "        you can use `noise_shape=(batch_size, 1, features)`.\n",
    "      seed: A Python integer to use as random seed.\n",
    "\n",
    "    Call arguments:\n",
    "      inputs: Input tensor (of any rank).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, rate=0.30, noise_shape=None, seed=None, **kwargs):\n",
    "        super().__init__(seed=seed, **kwargs)\n",
    "        if isinstance(rate, (int, float)) and not 0 <= rate <= 1:\n",
    "            raise ValueError(\n",
    "                f\"Invalid value {rate} received for \"\n",
    "                f\"`rate`, expected a value between 0 and 1.\"\n",
    "            )\n",
    "        self.rate = rate\n",
    "        self.noise_shape = noise_shape\n",
    "        self.seed = seed\n",
    "        self.supports_masking = True\n",
    "\n",
    "    def _get_noise_shape(self, inputs):\n",
    "        # Subclasses of `Dropout` may implement `_get_noise_shape(self,\n",
    "        # inputs)`, which will override `self.noise_shape`, and allows for\n",
    "        # custom noise shapes with dynamically sized inputs.\n",
    "        if self.noise_shape is None:\n",
    "            return None\n",
    "\n",
    "        concrete_inputs_shape = tf.shape(inputs)\n",
    "        noise_shape = []\n",
    "        for i, value in enumerate(self.noise_shape):\n",
    "            noise_shape.append(\n",
    "                concrete_inputs_shape[i] if value is None else value\n",
    "            )\n",
    "        return tf.convert_to_tensor(noise_shape)\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "\n",
    "        output = self._random_generator.dropout(\n",
    "                inputs, self.rate, noise_shape=self._get_noise_shape(inputs))\n",
    "        \n",
    "        return output\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\n",
    "            \"rate\": self.rate,\n",
    "            \"noise_shape\": self.noise_shape,\n",
    "            \"seed\": self.seed,\n",
    "        }\n",
    "        base_config = super().get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LaplaceApproximation(tf.keras.Model):\n",
    "\n",
    "    def __init__(self,model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.mean = None\n",
    "        self.std = None\n",
    "        self.lam = None\n",
    "\n",
    "    def fit(self,dataset,training=False):\n",
    "        \"\"\"\n",
    "        Fit the Laplace approximation for a model. Setting the mean of the Laplace approximation to the weights of the model \n",
    "            and, using the diagonal of the Fisher matrix, set the standard deviation of the Laplace approximation.\n",
    "        :param model: Model whose Fisher matrix is to be computed.\n",
    "        :param dataset: Dataset which the model has been trained on, but which will not be seen in the future. \n",
    "            Formatted as (inputs, labels).\n",
    "        :param samples: Number of samples to take from the dataset. More samples\n",
    "            gives a better approximation of the true variance.\n",
    "        \"\"\"\n",
    "        inputs, labels = dataset\n",
    "        trainable_weights = self.model.trainable_weights\n",
    "        variance = [tf.zeros_like(tensor) for tensor in trainable_weights]\n",
    "        n_epochs = 3\n",
    "        pb = tf.keras.utils.Progbar(inputs.shape[0])\n",
    "        for e in range(n_epochs):\n",
    "          for i in range(inputs.shape[0]):\n",
    "              pb.update(i)\n",
    "              index = i#np.random.randint(len(inputs))\n",
    "              # Select an element from the dataset.\n",
    "              data = inputs[index]\n",
    "              target = labels[index]\n",
    "\n",
    "              # When extracting from the array we lost a dimension so put it back.\n",
    "              data = tf.expand_dims(data, axis=0)\n",
    "\n",
    "              # Collect gradients.\n",
    "              with tf.GradientTape() as tape:\n",
    "                  output = self.model(data,training=training)\n",
    "                  log_likelihood = output.log_prob(target)\n",
    "\n",
    "              gradients = tape.gradient(log_likelihood, trainable_weights)\n",
    "\n",
    "              # If the model has converged, we can assume that the current weights\n",
    "              # are the mean, and each gradient we see is a deviation. The variance is\n",
    "              # the average of the square of this deviation.\n",
    "              variance = [var + (grad ** 2)/n_epochs for var, grad in zip(variance, gradients)]\n",
    "\n",
    "        self.fisher_diagonal = [tensor.numpy() for tensor in variance]\n",
    "        #self.fisher_diagonal = [tensor.numpy() / samples * inputs.shape[0] for tensor in variance]\n",
    "        \n",
    "        mins = [np.min(f) for f in self.fisher_diagonal]\n",
    "        for i,x in enumerate(mins):\n",
    "          if i==0 or min > x:\n",
    "            min = x\n",
    "        print(min)\n",
    "        #print('FISHER')\n",
    "        #print(fisher_diagonal)\n",
    "        self.mean = self.model.get_weights()       \n",
    "        \n",
    "\n",
    "    def reset_weights(self):\n",
    "        if self.mean:\n",
    "            self.model.set_weights(self.mean)\n",
    "\n",
    "    def set_std(self, weight_decay):\n",
    "      self.std = [np.reciprocal(np.sqrt(x+weight_decay)) for x in self.fisher_diagonal]\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        e = [np.random.standard_normal(x.shape) for x in self.mean]\n",
    "        sample = [m+s*e for m, s, e in zip(self.mean,self.std,e)]\n",
    "        self.model.set_weights(sample)\n",
    "        return self.model(inputs,training=training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MC Dropout Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span>1.</span> Train a neural network with dropout and a Bernoulli prediction for the ionosphere dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"IonosphereMCDropout\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_16 (InputLayer)       [(None, 33)]              0         \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 10)                340       \n",
      "                                                                 \n",
      " mc_dropout_21 (MCDropout)   (None, 10)                0         \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 10)                110       \n",
      "                                                                 \n",
      " mc_dropout_22 (MCDropout)   (None, 10)                0         \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 10)                110       \n",
      "                                                                 \n",
      " mc_dropout_23 (MCDropout)   (None, 10)                0         \n",
      "                                                                 \n",
      " p_val (Dense)               (None, 1)                 11        \n",
      "                                                                 \n",
      " output (DistributionLambda)  ((None, 1),              0         \n",
      "                              (None, 1))                         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 571\n",
      "Trainable params: 571\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "l2_reg = tf.keras.regularizers.l2(l2=0.00001)\n",
    "\n",
    "input = tf.keras.layers.Input(33)\n",
    "h1 = tf.keras.layers.Dense(10,activation=tf.keras.activations.relu,kernel_regularizer=l2_reg,bias_regularizer=l2_reg)(input)\n",
    "h1 = MCDropout(rate=0.5)(h1)\n",
    "h2 = tf.keras.layers.Dense(10,activation=tf.keras.activations.relu,kernel_regularizer=l2_reg,bias_regularizer=l2_reg)(h1)\n",
    "h2 = MCDropout(rate=0.5)(h2)\n",
    "h3 = tf.keras.layers.Dense(10,activation=tf.keras.activations.relu,kernel_regularizer=l2_reg,bias_regularizer=l2_reg)(h2)\n",
    "h3 = MCDropout(rate=0.5)(h3)\n",
    "p_val = tf.keras.layers.Dense(1, activation=tf.keras.activations.sigmoid, name=\"p_val\")(h3)\n",
    "out = tfp.layers.DistributionLambda(lambda t: tfp.distributions.Bernoulli(probs=t,  dtype=tf.float64), name=\"output\")(p_val)\n",
    "\n",
    "model = tf.keras.Model(inputs=input, outputs=out, name=\"IonosphereMCDropout\")\n",
    "\n",
    "model.compile(optimizer=tf.optimizers.Adam(learning_rate=0.00001), loss=expectNLL)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2e044fce20>"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x, y, epochs=50, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span>2.</span> Find the estimated aleatoric and epistemic uncertainty for all ionosphere examples using MC dropout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0026\n",
      "11/11 [==============================] - 0s 2ms/step\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0029\n",
      "11/11 [==============================] - 0s 2ms/step\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0028\n",
      "11/11 [==============================] - 0s 2ms/step\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0026\n",
      "11/11 [==============================] - 0s 2ms/step\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0025\n",
      "11/11 [==============================] - 0s 2ms/step\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0027\n",
      "11/11 [==============================] - 0s 2ms/step\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0026\n",
      "11/11 [==============================] - 0s 2ms/step\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0028\n",
      "11/11 [==============================] - 0s 2ms/step\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0027\n",
      "11/11 [==============================] - 0s 2ms/step\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0025\n",
      "11/11 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "preds = []\n",
    "weight_arr = []\n",
    "for _ in range(10):\n",
    "    model.fit(x,y)\n",
    "    y_dist = model(x)\n",
    "    yhat = model.predict(x)\n",
    "    preds.append(yhat)\n",
    "    weights = [np.squeeze(w.numpy()) for w in model.weights]\n",
    "    res = 0\n",
    "    for weight in weights:\n",
    "        res += np.mean(weight)\n",
    "    weight_arr.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epistemic Uncertainty: 2.9636262827738073e-07\n"
     ]
    }
   ],
   "source": [
    "result = np.var(weight_arr)\n",
    "print('Epistemic Uncertainty:', result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aleatoric Uncertainty: 7.426827041385398\n"
     ]
    }
   ],
   "source": [
    "bce = tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
    "print('Aleatoric Uncertainty:', bce(y, yhat).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MC Dropout with Laplace Approximation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span>3.</span> Find the Laplace approximation of the neural network with MC dropout that was trained in answer to\n",
    "question 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "347/351 [============================>.] - ETA: 0s0.0\n"
     ]
    }
   ],
   "source": [
    "la = LaplaceApproximation(model)\n",
    "la.fit([x,y])\n",
    "la.set_std(weight_decay=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span>4.</span> Find the estimated aleatoric and epistemic uncertainty for all ionosphere examples using MC dropout\n",
    "and the Laplace approximation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "348/351 [============================>.] - ETA: 0s0.0\n",
      "11/11 [==============================] - 0s 2ms/step\n",
      "350/351 [============================>.] - ETA: 0s0.0\n",
      "11/11 [==============================] - 0s 2ms/step\n",
      "347/351 [============================>.] - ETA: 0s0.0\n",
      "11/11 [==============================] - 0s 2ms/step\n",
      "348/351 [============================>.] - ETA: 0s0.0\n",
      "11/11 [==============================] - 0s 2ms/step\n",
      "348/351 [============================>.] - ETA: 0s0.0\n",
      "11/11 [==============================] - 0s 2ms/step\n",
      "350/351 [============================>.] - ETA: 0s0.0\n",
      "11/11 [==============================] - 0s 2ms/step\n",
      "348/351 [============================>.] - ETA: 0s0.0\n",
      "11/11 [==============================] - 0s 2ms/step\n",
      "349/351 [============================>.] - ETA: 0s0.0\n",
      "11/11 [==============================] - 0s 2ms/step\n",
      "347/351 [============================>.] - ETA: 0s0.0\n",
      "11/11 [==============================] - 0s 2ms/step\n",
      "349/351 [============================>.] - ETA: 0s0.0\n",
      "11/11 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "preds = []\n",
    "weight_arr = []\n",
    "for _ in range(10):\n",
    "    la = LaplaceApproximation(model)\n",
    "    la.fit([x,y])\n",
    "    la.set_std(weight_decay=1000)\n",
    "    la_dist = la(x)\n",
    "    yhat = la.predict(x)\n",
    "    preds.append(yhat)\n",
    "    weights = [np.squeeze(w.numpy()) for w in la.weights]\n",
    "    res = 0\n",
    "    for weight in weights:\n",
    "        res += np.mean(weight)\n",
    "    weight_arr.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epistemic Uncertainty: 0.0014887651228679326\n"
     ]
    }
   ],
   "source": [
    "result = np.var(weight_arr)\n",
    "print('Epistemic Uncertainty:', result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aleatoric Uncertainty: 7.514718485656673\n"
     ]
    }
   ],
   "source": [
    "bce = tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
    "print('Aleatoric Uncertainty:', bce(y, yhat).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MC Dropout Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span>5.</span> Train a neural network with MC dropout and a Bernoulli prediction for the ionosphere dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"IonosphereMCDropout2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_15 (InputLayer)       [(None, 33)]              0         \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 10)                340       \n",
      "                                                                 \n",
      " mc_dropout_20 (MCDropout)   (None, 10)                0         \n",
      "                                                                 \n",
      " p_val (Dense)               (None, 1)                 11        \n",
      "                                                                 \n",
      " output (DistributionLambda)  ((None, 1),              0         \n",
      "                              (None, 1))                         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 351\n",
      "Trainable params: 351\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "input1 = tf.keras.layers.Input(33)\n",
    "h1 = tf.keras.layers.Dense(10,activation=tf.keras.activations.relu,kernel_regularizer=l2_reg,bias_regularizer=l2_reg)(input1)\n",
    "h1 = MCDropout(rate=0.2)(h1)\n",
    "p_val = tf.keras.layers.Dense(1, activation=tf.keras.activations.sigmoid, name=\"p_val\")(h1)\n",
    "out1 = tfp.layers.DistributionLambda(lambda t: tfp.distributions.Bernoulli(probs=t,  dtype=tf.float64), name=\"output\")(p_val)\n",
    "\n",
    "model2 = tf.keras.Model(inputs=input1, outputs=out1, name=\"IonosphereMCDropout2\")\n",
    "\n",
    "model2.compile(optimizer=tf.optimizers.Adam(learning_rate=0.0000000001), loss=expectNLL)\n",
    "print(model2.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2e6429c430>"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(x, y, epochs=50, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span>6. Find the estimated aleatoric and epistemic uncertainty for all ionosphere test examples using MC\n",
    "dropout.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0031\n",
      "11/11 [==============================] - 0s 2ms/step\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0031\n",
      "11/11 [==============================] - 0s 2ms/step\n",
      "11/11 [==============================] - 0s 3ms/step - loss: 0.0031\n",
      "11/11 [==============================] - 0s 2ms/step\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0030\n",
      "11/11 [==============================] - 0s 2ms/step\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0032\n",
      "11/11 [==============================] - 0s 2ms/step\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0032\n",
      "11/11 [==============================] - 0s 2ms/step\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0031\n",
      "11/11 [==============================] - 0s 2ms/step\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0032\n",
      "11/11 [==============================] - 0s 2ms/step\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0031\n",
      "11/11 [==============================] - 0s 2ms/step\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.0030\n",
      "11/11 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "preds = []\n",
    "weight_arr = []\n",
    "for _ in range(10):\n",
    "    model2.fit(x,y)\n",
    "    y_dist = model2(x)\n",
    "    yhat = model2.predict(x)\n",
    "    preds.append(yhat)\n",
    "    weights = [np.squeeze(w.numpy()) for w in model2.weights]\n",
    "    res = 0\n",
    "    for weight in weights:\n",
    "        res += np.mean(weight)\n",
    "    weight_arr.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epistemic Uncertainty: 1.289778403533695e-17\n"
     ]
    }
   ],
   "source": [
    "result = np.var(weight_arr)\n",
    "print('Epistemic Uncertainty:', result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aleatoric Uncertainty: 8.613361539110599\n"
     ]
    }
   ],
   "source": [
    "bce = tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
    "print('Aleatoric Uncertainty:', bce(y, yhat).numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
