{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naval Propulsion Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "naval_data = pd.read_csv('naval.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11934 entries, 0 to 11933\n",
      "Data columns (total 18 columns):\n",
      " #   Column                                              Non-Null Count  Dtype  \n",
      "---  ------                                              --------------  -----  \n",
      " 0   1 - Lever position (lp) [ ]                         11934 non-null  float64\n",
      " 1   2 - Ship speed (v) [knots]                          11934 non-null  float64\n",
      " 2   3 - Gas Turbine shaft torque (GTT) [kN m]           11934 non-null  float64\n",
      " 3   4 - Gas Turbine rate of revolutions (GTn) [rpm]     11934 non-null  float64\n",
      " 4   5 - Gas Generator rate of revolutions (GGn) [rpm]   11934 non-null  float64\n",
      " 5   6 - Starboard Propeller Torque (Ts) [kN]            11934 non-null  float64\n",
      " 6   7 - Port Propeller Torque (Tp) [kN]                 11934 non-null  float64\n",
      " 7   8 - HP Turbine exit temperature (T48) [C]           11934 non-null  float64\n",
      " 8   9 - GT Compressor inlet air temperature (T1) [C]    11934 non-null  float64\n",
      " 9   10 - GT Compressor outlet air temperature (T2) [C]  11934 non-null  float64\n",
      " 10  11 - HP Turbine exit pressure (P48) [bar]           11934 non-null  float64\n",
      " 11  12 - GT Compressor inlet air pressure (P1) [bar]    11934 non-null  float64\n",
      " 12  13 - GT Compressor outlet air pressure (P2) [bar]   11934 non-null  float64\n",
      " 13  14 - Gas Turbine exhaust gas pressure (Pexh) [bar]  11934 non-null  float64\n",
      " 14  15 - Turbine Injecton Control (TIC) [%]             11934 non-null  float64\n",
      " 15  16 - Fuel flow (mf) [kg/s]                          11934 non-null  float64\n",
      " 16  17 - GT Compressor decay state coefficient.         11934 non-null  float64\n",
      " 17  18 - GT Turbine decay state coefficient.            11934 non-null  float64\n",
      "dtypes: float64(18)\n",
      "memory usage: 1.6 MB\n"
     ]
    }
   ],
   "source": [
    "naval_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "RangeIndex: 11934 entries, 0 to 11933\n",
      "Series name: 17 - GT Compressor decay state coefficient.\n",
      "Non-Null Count  Dtype  \n",
      "--------------  -----  \n",
      "11934 non-null  float64\n",
      "dtypes: float64(1)\n",
      "memory usage: 93.4 KB\n",
      "0        0.95\n",
      "1        0.95\n",
      "2        0.95\n",
      "3        0.95\n",
      "4        0.95\n",
      "         ... \n",
      "11929    1.00\n",
      "11930    1.00\n",
      "11931    1.00\n",
      "11932    1.00\n",
      "11933    1.00\n",
      "Name: 17 - GT Compressor decay state coefficient., Length: 11934, dtype: float64\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11934 entries, 0 to 11933\n",
      "Data columns (total 16 columns):\n",
      " #   Column                                              Non-Null Count  Dtype  \n",
      "---  ------                                              --------------  -----  \n",
      " 0   1 - Lever position (lp) [ ]                         11934 non-null  float64\n",
      " 1   2 - Ship speed (v) [knots]                          11934 non-null  float64\n",
      " 2   3 - Gas Turbine shaft torque (GTT) [kN m]           11934 non-null  float64\n",
      " 3   4 - Gas Turbine rate of revolutions (GTn) [rpm]     11934 non-null  float64\n",
      " 4   5 - Gas Generator rate of revolutions (GGn) [rpm]   11934 non-null  float64\n",
      " 5   6 - Starboard Propeller Torque (Ts) [kN]            11934 non-null  float64\n",
      " 6   7 - Port Propeller Torque (Tp) [kN]                 11934 non-null  float64\n",
      " 7   8 - HP Turbine exit temperature (T48) [C]           11934 non-null  float64\n",
      " 8   9 - GT Compressor inlet air temperature (T1) [C]    11934 non-null  float64\n",
      " 9   10 - GT Compressor outlet air temperature (T2) [C]  11934 non-null  float64\n",
      " 10  11 - HP Turbine exit pressure (P48) [bar]           11934 non-null  float64\n",
      " 11  12 - GT Compressor inlet air pressure (P1) [bar]    11934 non-null  float64\n",
      " 12  13 - GT Compressor outlet air pressure (P2) [bar]   11934 non-null  float64\n",
      " 13  14 - Gas Turbine exhaust gas pressure (Pexh) [bar]  11934 non-null  float64\n",
      " 14  15 - Turbine Injecton Control (TIC) [%]             11934 non-null  float64\n",
      " 15  16 - Fuel flow (mf) [kg/s]                          11934 non-null  float64\n",
      "dtypes: float64(16)\n",
      "memory usage: 1.5 MB\n"
     ]
    }
   ],
   "source": [
    "y = naval_data[naval_data.columns[16]]\n",
    "X = naval_data.iloc[:,0:16]\n",
    "y.info()\n",
    "print(y)\n",
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.53324812 -1.54919334 -1.2166697  ... -0.9486833  -1.02557391\n",
      "  -1.14440517]\n",
      " [-1.17161304 -1.161895   -0.91565197 ... -0.9486833  -0.88780617\n",
      "  -0.7403042 ]\n",
      " [-0.77191112 -0.77459667 -0.85156724 ... -0.9486833  -0.79492904\n",
      "  -0.79549848]\n",
      " ...\n",
      " [ 0.75456956  0.77459667  0.53031625 ...  0.9486833   0.32733629\n",
      "   0.33795544]\n",
      " [ 1.15807816  1.161895    1.07187738 ...  0.9486833   0.94651716\n",
      "   0.96086229]\n",
      " [ 1.57300683  1.54919334  2.05571343 ...  1.8973666   2.03008369\n",
      "   2.04503561]]\n",
      "[[-1.69841555]\n",
      " [-1.69841555]\n",
      " [-1.69841555]\n",
      " ...\n",
      " [ 1.69841555]\n",
      " [ 1.69841555]\n",
      " [ 1.69841555]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler_X = StandardScaler()\n",
    "scaler_y = StandardScaler()\n",
    "\n",
    "X = scaler_X.fit_transform(X)\n",
    "y = y.to_numpy()\n",
    "y = y.reshape(-1,1)\n",
    "y = scaler_y.fit_transform(y)\n",
    "\n",
    "print(X)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_examples = y.shape[0]\n",
    "expectNLL = lambda y, rv_y: -rv_y.log_prob(y)/n_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"NavalModel\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 16)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "hidden1 (Dense)                 (None, 50)           850         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "hidden2 (Dense)                 (None, 50)           2550        hidden1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "hidden3 (Dense)                 (None, 20)           1020        hidden2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "mu (Dense)                      (None, 1)            21          hidden3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sigma_L2_reg (Dense)            (None, 1)            21          hidden3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "output (DistributionLambda)     multiple             0           mu[0][0]                         \n",
      "                                                                 sigma_L2_reg[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 4,462\n",
      "Trainable params: 4,462\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-06 23:40:08.870517: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/extras/CUPTI/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2023-02-06 23:40:08.871865: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/extras/CUPTI/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2023-02-06 23:40:08.871901: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1835] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2023-02-06 23:40:08.872263: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-02-06 23:40:08.971227: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    }
   ],
   "source": [
    "l2_reg = tf.keras.regularizers.L2(l2=0.05)\n",
    "\n",
    "input = tf.keras.layers.Input(16)\n",
    "h1 = tf.keras.layers.Dense(50, activation=tf.keras.activations.relu, name=\"hidden1\")(input)\n",
    "h2 = tf.keras.layers.Dense(50, activation=tf.keras.activations.relu, name=\"hidden2\")(h1)\n",
    "h3 = tf.keras.layers.Dense(20, activation=tf.keras.activations.relu, name=\"hidden3\")(h2)\n",
    "m2 = tf.keras.layers.Dense(1, name=\"mu\", kernel_regularizer=l2_reg,bias_regularizer=l2_reg)(h3)\n",
    "s2 = tf.keras.layers.Dense(1,activation=tf.keras.activations.exponential,kernel_regularizer=l2_reg, bias_regularizer=l2_reg, name=\"sigma_L2_reg\")(h3)\n",
    "p2 = tfp.layers.DistributionLambda(lambda t: tfp.distributions.Normal(loc=t[0], scale=t[1]), name=\"output\")([m2, s2])\n",
    "model = tf.keras.Model(inputs=input, outputs=p2, name=\"NavalModel\")\n",
    "\n",
    "model.compile(optimizer=tf.optimizers.Adam(learning_rate=0.01), loss=expectNLL)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-06 23:40:09.062658: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "373/373 [==============================] - 1s 2ms/step - loss: 0.0059\n",
      "Epoch 2/100\n",
      "373/373 [==============================] - 0s 1ms/step - loss: 1.1893e-04\n",
      "Epoch 3/100\n",
      "373/373 [==============================] - 0s 1ms/step - loss: 1.1893e-04\n",
      "Epoch 4/100\n",
      "373/373 [==============================] - 0s 1ms/step - loss: 1.1894e-04\n",
      "Epoch 5/100\n",
      "373/373 [==============================] - 0s 1ms/step - loss: 1.1896e-04\n",
      "Epoch 6/100\n",
      "373/373 [==============================] - 0s 1ms/step - loss: 1.1895e-04\n",
      "Epoch 7/100\n",
      "373/373 [==============================] - 0s 1ms/step - loss: 1.1896e-04\n",
      "Epoch 8/100\n",
      "373/373 [==============================] - 0s 1ms/step - loss: 1.1895e-04\n",
      "Epoch 9/100\n",
      "373/373 [==============================] - 0s 1ms/step - loss: 1.1896e-04\n",
      "Epoch 10/100\n",
      "373/373 [==============================] - 0s 1ms/step - loss: 1.1896e-04\n",
      "Epoch 11/100\n",
      "373/373 [==============================] - 0s 1ms/step - loss: 1.1898e-04\n",
      "Epoch 12/100\n",
      "373/373 [==============================] - 0s 1ms/step - loss: 1.1897e-04\n",
      "Epoch 13/100\n",
      "373/373 [==============================] - 0s 1ms/step - loss: 1.1897e-04\n",
      "Epoch 14/100\n",
      "373/373 [==============================] - 0s 1ms/step - loss: 1.1898e-04\n",
      "Epoch 15/100\n",
      "373/373 [==============================] - 0s 1ms/step - loss: 1.1897e-04\n",
      "Epoch 16/100\n",
      "373/373 [==============================] - 0s 1ms/step - loss: 1.1897e-04\n",
      "Epoch 17/100\n",
      "373/373 [==============================] - 0s 1ms/step - loss: 1.1898e-04\n",
      "Epoch 18/100\n",
      "373/373 [==============================] - 0s 1ms/step - loss: 1.1897e-04\n",
      "Epoch 19/100\n",
      "373/373 [==============================] - 0s 1ms/step - loss: 1.1897e-04\n",
      "Epoch 20/100\n",
      "373/373 [==============================] - 0s 1ms/step - loss: 1.1899e-04\n",
      "Epoch 21/100\n",
      "373/373 [==============================] - 0s 1ms/step - loss: 1.1902e-04\n",
      "Epoch 22/100\n",
      "373/373 [==============================] - 0s 1ms/step - loss: 1.1904e-04\n",
      "Epoch 23/100\n",
      "373/373 [==============================] - 0s 1ms/step - loss: 1.1903e-04\n",
      "Epoch 24/100\n",
      "373/373 [==============================] - 1s 1ms/step - loss: 1.1904e-04\n",
      "Epoch 25/100\n",
      "373/373 [==============================] - 0s 1ms/step - loss: 1.1908e-04\n",
      "Epoch 26/100\n",
      "373/373 [==============================] - 0s 1ms/step - loss: 1.1914e-04\n",
      "Epoch 27/100\n",
      "373/373 [==============================] - 0s 1ms/step - loss: 1.1911e-04\n",
      "Epoch 28/100\n",
      "373/373 [==============================] - 0s 1ms/step - loss: 1.1918e-04\n",
      "Epoch 29/100\n",
      "373/373 [==============================] - 0s 1ms/step - loss: 1.1916e-04\n",
      "Epoch 30/100\n",
      "373/373 [==============================] - 0s 1ms/step - loss: 1.1912e-04\n",
      "Epoch 31/100\n",
      "373/373 [==============================] - 0s 1ms/step - loss: 1.1942e-04\n",
      "Epoch 32/100\n",
      "373/373 [==============================] - 0s 1ms/step - loss: 1.1912e-04\n",
      "Epoch 33/100\n",
      "373/373 [==============================] - 0s 1ms/step - loss: 1.1910e-04\n",
      "Epoch 34/100\n",
      "373/373 [==============================] - 0s 1ms/step - loss: 1.1911e-04\n",
      "Epoch 35/100\n",
      "373/373 [==============================] - 0s 1ms/step - loss: 1.1918e-04\n",
      "Epoch 36/100\n",
      "373/373 [==============================] - 0s 1ms/step - loss: 1.1917e-04\n",
      "Epoch 37/100\n",
      "373/373 [==============================] - 0s 1ms/step - loss: 1.1907e-04\n",
      "Epoch 38/100\n",
      "373/373 [==============================] - 0s 1ms/step - loss: 1.1909e-04\n",
      "Epoch 39/100\n",
      "373/373 [==============================] - 0s 1ms/step - loss: 1.1908e-04\n",
      "Epoch 40/100\n",
      "373/373 [==============================] - 0s 1ms/step - loss: 1.1907e-04\n",
      "Epoch 41/100\n",
      "373/373 [==============================] - 0s 1ms/step - loss: 1.1956e-04\n",
      "Epoch 42/100\n",
      "373/373 [==============================] - 0s 1ms/step - loss: 1.1907e-04\n",
      "Epoch 43/100\n",
      "373/373 [==============================] - 0s 1ms/step - loss: 1.1904e-04\n",
      "Epoch 44/100\n",
      "373/373 [==============================] - 0s 1ms/step - loss: 1.1903e-04\n",
      "Epoch 45/100\n",
      "373/373 [==============================] - 0s 1ms/step - loss: 1.1904e-04\n",
      "Epoch 46/100\n",
      "373/373 [==============================] - 0s 1ms/step - loss: 1.1905e-04\n",
      "Epoch 47/100\n",
      "373/373 [==============================] - 0s 1ms/step - loss: 1.1909e-04\n",
      "Epoch 48/100\n",
      "373/373 [==============================] - 0s 1ms/step - loss: 1.1905e-04\n",
      "Epoch 49/100\n",
      "373/373 [==============================] - 0s 1ms/step - loss: 1.1906e-04\n",
      "Epoch 50/100\n",
      "373/373 [==============================] - 0s 1ms/step - loss: 1.1907e-04\n",
      "Epoch 51/100\n",
      "373/373 [==============================] - 0s 1ms/step - loss: 1.1905e-04\n",
      "Epoch 52/100\n",
      "373/373 [==============================] - 1s 1ms/step - loss: 1.2032e-04\n",
      "Epoch 53/100\n",
      "373/373 [==============================] - 1s 1ms/step - loss: 1.1909e-04\n",
      "Epoch 54/100\n",
      "373/373 [==============================] - 0s 1ms/step - loss: 1.1914e-04\n",
      "Epoch 55/100\n",
      "373/373 [==============================] - 0s 1ms/step - loss: 1.1907e-04\n",
      "Epoch 56/100\n",
      "373/373 [==============================] - 0s 1ms/step - loss: 1.1907e-04\n",
      "Epoch 57/100\n",
      "373/373 [==============================] - 0s 1ms/step - loss: 1.1909e-04\n",
      "Epoch 58/100\n",
      "373/373 [==============================] - 0s 1ms/step - loss: 1.1907e-04\n",
      "Epoch 59/100\n",
      "373/373 [==============================] - 0s 1ms/step - loss: 1.1913e-04\n",
      "Epoch 60/100\n",
      "373/373 [==============================] - 0s 1ms/step - loss: 1.1906e-04\n",
      "Epoch 61/100\n",
      "373/373 [==============================] - 0s 1ms/step - loss: 1.1905e-04\n",
      "Epoch 62/100\n",
      "373/373 [==============================] - 0s 1ms/step - loss: 1.1915e-04\n",
      "Epoch 63/100\n",
      "373/373 [==============================] - 0s 1ms/step - loss: 1.1986e-04\n",
      "Epoch 64/100\n",
      "373/373 [==============================] - 0s 1ms/step - loss: 1.1908e-04\n",
      "Epoch 65/100\n",
      "373/373 [==============================] - 0s 1ms/step - loss: 1.1909e-04\n",
      "Epoch 66/100\n",
      "373/373 [==============================] - 0s 1ms/step - loss: 1.1911e-04\n",
      "Epoch 67/100\n",
      "373/373 [==============================] - 0s 1ms/step - loss: 1.1914e-04\n",
      "Epoch 68/100\n",
      "373/373 [==============================] - 0s 1ms/step - loss: 1.1910e-04\n",
      "Epoch 69/100\n",
      "373/373 [==============================] - 0s 1ms/step - loss: 1.1913e-04\n",
      "Epoch 70/100\n",
      "373/373 [==============================] - 0s 1ms/step - loss: 1.1915e-04\n",
      "Epoch 71/100\n",
      "373/373 [==============================] - 0s 1ms/step - loss: 1.1929e-04\n",
      "Epoch 72/100\n",
      "373/373 [==============================] - 0s 1ms/step - loss: 1.1938e-04\n",
      "Epoch 73/100\n",
      "373/373 [==============================] - 0s 1ms/step - loss: 1.1934e-04\n",
      "Epoch 74/100\n",
      "373/373 [==============================] - 0s 1ms/step - loss: 1.1909e-04\n",
      "Epoch 75/100\n",
      "373/373 [==============================] - 0s 1ms/step - loss: 1.1910e-04\n",
      "Epoch 76/100\n",
      "373/373 [==============================] - 0s 1ms/step - loss: 1.1910e-04\n",
      "Epoch 77/100\n",
      "373/373 [==============================] - 0s 1ms/step - loss: 1.1912e-04\n",
      "Epoch 78/100\n",
      "373/373 [==============================] - 0s 1ms/step - loss: 1.1970e-04\n",
      "Epoch 79/100\n",
      "373/373 [==============================] - 0s 1ms/step - loss: 1.1908e-04\n",
      "Epoch 80/100\n",
      "373/373 [==============================] - 0s 1ms/step - loss: 1.1912e-04\n",
      "Epoch 81/100\n",
      "373/373 [==============================] - 0s 1ms/step - loss: 1.1906e-04\n",
      "Epoch 82/100\n",
      "373/373 [==============================] - 0s 1ms/step - loss: 1.1909e-04\n",
      "Epoch 83/100\n",
      "373/373 [==============================] - 0s 1ms/step - loss: 1.1909e-04\n",
      "Epoch 84/100\n",
      "373/373 [==============================] - 0s 1ms/step - loss: 1.1906e-04\n",
      "Epoch 85/100\n",
      "373/373 [==============================] - 0s 1ms/step - loss: 1.1993e-04\n",
      "Epoch 86/100\n",
      "373/373 [==============================] - 1s 1ms/step - loss: 1.1920e-04\n",
      "Epoch 87/100\n",
      "373/373 [==============================] - 0s 1ms/step - loss: 1.1909e-04\n",
      "Epoch 88/100\n",
      "373/373 [==============================] - 0s 1ms/step - loss: 1.1907e-04\n",
      "Epoch 89/100\n",
      "373/373 [==============================] - 0s 1ms/step - loss: 1.1906e-04\n",
      "Epoch 90/100\n",
      "373/373 [==============================] - 0s 1ms/step - loss: 1.1907e-04\n",
      "Epoch 91/100\n",
      "373/373 [==============================] - 0s 1ms/step - loss: 1.1907e-04\n",
      "Epoch 92/100\n",
      "373/373 [==============================] - 0s 1ms/step - loss: 1.1907e-04\n",
      "Epoch 93/100\n",
      "373/373 [==============================] - 0s 1ms/step - loss: 1.1906e-04\n",
      "Epoch 94/100\n",
      "373/373 [==============================] - 0s 1ms/step - loss: 1.1906e-04\n",
      "Epoch 95/100\n",
      "373/373 [==============================] - 0s 1ms/step - loss: 1.1907e-04\n",
      "Epoch 96/100\n",
      "373/373 [==============================] - 0s 1ms/step - loss: 1.1907e-04\n",
      "Epoch 97/100\n",
      "373/373 [==============================] - 1s 1ms/step - loss: 1.1906e-04\n",
      "Epoch 98/100\n",
      "373/373 [==============================] - 1s 1ms/step - loss: 1.1907e-04\n",
      "Epoch 99/100\n",
      "373/373 [==============================] - 0s 1ms/step - loss: 1.1909e-04\n",
      "Epoch 100/100\n",
      "373/373 [==============================] - 1s 1ms/step - loss: 1.1908e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8abc1cb5e0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, epochs=100, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9704076 ]\n",
      " [0.9771641 ]\n",
      " [0.96479225]\n",
      " ...\n",
      " [0.9456068 ]\n",
      " [0.9889828 ]\n",
      " [0.9506123 ]]\n"
     ]
    }
   ],
   "source": [
    "yhat = model.predict(X)\n",
    "yhat = scaler_y.inverse_transform(yhat)\n",
    "print(yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.3967553122560445\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "print('RMSE:', np.sqrt(mean_squared_error(y, yhat)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Laplace Approximation copied from Model Code notebook\n",
    "\n",
    "class LaplaceApproximation(tf.keras.Model):\n",
    "\n",
    "    def __init__(self,model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.mean = None\n",
    "        self.std = None\n",
    "        self.lam = None\n",
    "\n",
    "    def fit(self,dataset,training=False):\n",
    "        \"\"\"\n",
    "        Fit the Laplace approximation for a model. Setting the mean of the Laplace approximation to the weights of the model \n",
    "            and, using the diagonal of the Fisher matrix, set the standard deviation of the Laplace approximation.\n",
    "        :param model: Model whose Fisher matrix is to be computed.\n",
    "        :param dataset: Dataset which the model has been trained on, but which will not be seen in the future. \n",
    "            Formatted as (inputs, labels).\n",
    "        :param samples: Number of samples to take from the dataset. More samples\n",
    "            gives a better approximation of the true variance.\n",
    "        \"\"\"\n",
    "        inputs, labels = dataset\n",
    "        trainable_weights = self.model.trainable_weights\n",
    "        variance = [tf.zeros_like(tensor) for tensor in trainable_weights]\n",
    "        \n",
    "        pb = tf.keras.utils.Progbar(inputs.shape[0])\n",
    "\n",
    "        for i in range(inputs.shape[0]):\n",
    "            pb.update(i)\n",
    "            index = i#np.random.randint(len(inputs))\n",
    "            # Select an element from the dataset.\n",
    "            data = inputs[index]\n",
    "            target = labels[index]\n",
    "\n",
    "            # When extracting from the array we lost a dimension so put it back.\n",
    "            data = tf.expand_dims(data, axis=0)\n",
    "\n",
    "            # Collect gradients.\n",
    "            with tf.GradientTape() as tape:\n",
    "                output = self.model(data,training=training)\n",
    "                log_likelihood = output.log_prob(target)\n",
    "\n",
    "            gradients = tape.gradient(log_likelihood, trainable_weights)\n",
    "\n",
    "            # If the model has converged, we can assume that the current weights\n",
    "            # are the mean, and each gradient we see is a deviation. The variance is\n",
    "            # the average of the square of this deviation.\n",
    "            variance = [var + (grad ** 2) for var, grad in zip(variance, gradients)]\n",
    "\n",
    "        self.fisher_diagonal = [tensor.numpy() for tensor in variance]\n",
    "        #self.fisher_diagonal = [tensor.numpy() / samples * inputs.shape[0] for tensor in variance]\n",
    "        \n",
    "        mins = [np.min(f) for f in self.fisher_diagonal]\n",
    "        for i,x in enumerate(mins):\n",
    "          if i==0 or min > x:\n",
    "            min = x\n",
    "        print(min)\n",
    "        #print('FISHER')\n",
    "        #print(fisher_diagonal)\n",
    "        self.mean = self.model.get_weights()       \n",
    "        \n",
    "\n",
    "    def reset_weights(self):\n",
    "        if self.mean:\n",
    "            self.model.set_weights(self.mean)\n",
    "\n",
    "    def set_std(self, weight_decay):\n",
    "      self.std = [np.reciprocal(np.sqrt(x+weight_decay)) for x in self.fisher_diagonal]\n",
    "\n",
    "    def call(self, inputs, training=False):\n",
    "        e = [np.random.standard_normal(x.shape) for x in self.mean]\n",
    "        sample = [m+s*e for m, s, e in zip(self.mean,self.std,e)]\n",
    "        self.model.set_weights(sample)\n",
    "        return self.model(inputs,training=training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "la_model = LaplaceApproximation(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11932/11934 [============================>.] - ETA: 0s0.0\n"
     ]
    }
   ],
   "source": [
    "la_model.fit([X,y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "la_model.set_std(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9564295 ]\n",
      " [0.9748274 ]\n",
      " [0.9666824 ]\n",
      " ...\n",
      " [0.97935134]\n",
      " [1.0003133 ]\n",
      " [0.9823706 ]]\n"
     ]
    }
   ],
   "source": [
    "yhat2 = la_model.predict(X)\n",
    "yhat2 = scaler_y.inverse_transform(yhat2)\n",
    "print(yhat2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.3967553122560445\n"
     ]
    }
   ],
   "source": [
    "print('RMSE:', np.sqrt(mean_squared_error(y, yhat)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epistemic Uncertainty 0.0024254636\n"
     ]
    }
   ],
   "source": [
    "y_dist = la_model(X)\n",
    "means = y_dist.mean().numpy()\n",
    "print('Epistemic Uncertainty', means.var())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ionospheric Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method DataFrame.info of      0   1        2        3        4        5        6        7        8   \\\n",
      "0     1   0  0.99539 -0.05889  0.85243  0.02306  0.83398 -0.37708  1.00000   \n",
      "1     1   0  1.00000 -0.18829  0.93035 -0.36156 -0.10868 -0.93597  1.00000   \n",
      "2     1   0  1.00000 -0.03365  1.00000  0.00485  1.00000 -0.12062  0.88965   \n",
      "3     1   0  1.00000 -0.45161  1.00000  1.00000  0.71216 -1.00000  0.00000   \n",
      "4     1   0  1.00000 -0.02401  0.94140  0.06531  0.92106 -0.23255  0.77152   \n",
      "..   ..  ..      ...      ...      ...      ...      ...      ...      ...   \n",
      "346   1   0  0.83508  0.08298  0.73739 -0.14706  0.84349 -0.05567  0.90441   \n",
      "347   1   0  0.95113  0.00419  0.95183 -0.02723  0.93438 -0.01920  0.94590   \n",
      "348   1   0  0.94701 -0.00034  0.93207 -0.03227  0.95177 -0.03431  0.95584   \n",
      "349   1   0  0.90608 -0.01657  0.98122 -0.01989  0.95691 -0.03646  0.85746   \n",
      "350   1   0  0.84710  0.13533  0.73638 -0.06151  0.87873  0.08260  0.88928   \n",
      "\n",
      "          9   ...       25       26       27       28       29       30  \\\n",
      "0    0.03760  ... -0.51171  0.41078 -0.46168  0.21266 -0.34090  0.42267   \n",
      "1   -0.04549  ... -0.26569 -0.20468 -0.18401 -0.19040 -0.11593 -0.16626   \n",
      "2    0.01198  ... -0.40220  0.58984 -0.22145  0.43100 -0.17365  0.60436   \n",
      "3    0.00000  ...  0.90695  0.51613  1.00000  1.00000 -0.20099  0.25682   \n",
      "4   -0.16399  ... -0.65158  0.13290 -0.53206  0.02431 -0.62197 -0.05707   \n",
      "..       ...  ...      ...      ...      ...      ...      ...      ...   \n",
      "346 -0.04622  ... -0.04202  0.83479  0.00123  1.00000  0.12815  0.86660   \n",
      "347  0.01606  ...  0.01361  0.93522  0.04925  0.93159  0.08168  0.94066   \n",
      "348  0.02446  ...  0.03193  0.92489  0.02542  0.92120  0.02242  0.92459   \n",
      "349  0.00110  ... -0.02099  0.89147 -0.07760  0.82983 -0.17238  0.96022   \n",
      "350 -0.09139  ... -0.15114  0.81147 -0.04822  0.78207 -0.00703  0.75747   \n",
      "\n",
      "          31       32       33  34  \n",
      "0   -0.54487  0.18641 -0.45300   g  \n",
      "1   -0.06288 -0.13738 -0.02447   b  \n",
      "2   -0.24180  0.56045 -0.38238   g  \n",
      "3    1.00000 -0.32382  1.00000   b  \n",
      "4   -0.59573 -0.04608 -0.65697   g  \n",
      "..       ...      ...      ...  ..  \n",
      "346 -0.10714  0.90546 -0.04307   g  \n",
      "347 -0.00035  0.91483  0.04712   g  \n",
      "348  0.00442  0.92697 -0.00577   g  \n",
      "349 -0.03757  0.87403 -0.16243   g  \n",
      "350 -0.06678  0.85764 -0.06151   g  \n",
      "\n",
      "[351 rows x 35 columns]>\n"
     ]
    }
   ],
   "source": [
    "ion_data = pd.read_csv('ionosphere.csv', header=None)\n",
    "print(ion_data.info)\n",
    "\n",
    "n_examples = y.shape[0]\n",
    "expectNLL = lambda y, rv_y: -rv_y.log_prob(y)/n_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "g class: 0\n",
      "b class: 1\n",
      "[0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0\n",
      " 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1\n",
      " 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 0 1 0 1 0 1 0 1 0 1 0 1 0 1\n",
      " 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0\n",
      " 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1\n",
      " 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0\n",
      " 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "# One hot, label is last two columns\n",
    "def one_hot(cat, hot):\n",
    "    if cat == hot:\n",
    "        return int(1)\n",
    "    else:\n",
    "        return int(0)\n",
    "    \n",
    "ion_data[35] = ion_data[34].apply(one_hot, hot='g')\n",
    "ion_data[36] = ion_data[34].apply(one_hot, hot='b')\n",
    "\"\"\"\n",
    "\n",
    "def ordinal_encoder(category):\n",
    "    dict = {'g': 0, 'b': 1}\n",
    "    return dict[category]\n",
    "\n",
    "print('g class:', ordinal_encoder('g'))\n",
    "print('b class:', ordinal_encoder('b'))\n",
    "ion_data[34] = ion_data[34].apply(ordinal_encoder)\n",
    "print(ion_data[34].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(351, 33)\n",
      "(351, 1)\n"
     ]
    }
   ],
   "source": [
    "# split x and y\n",
    "x = ion_data.iloc[:,0:33].to_numpy()\n",
    "y = ion_data.iloc[:,34].to_numpy().reshape(-1,1)\n",
    "\n",
    "# Scaling\n",
    "scaler = StandardScaler()\n",
    "x = scaler.fit_transform(x)\n",
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"IonosphereNNMLEwDistr\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 33)]              0         \n",
      "_________________________________________________________________\n",
      "hidden1 (Dense)              (None, 10)                340       \n",
      "_________________________________________________________________\n",
      "hidden2 (Dense)              (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "hidden3 (Dense)              (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "p_val (Dense)                (None, 1)                 11        \n",
      "_________________________________________________________________\n",
      "output (DistributionLambda)  multiple                  0         \n",
      "=================================================================\n",
      "Total params: 571\n",
      "Trainable params: 571\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "input2 = tf.keras.layers.Input(33)\n",
    "h21 = tf.keras.layers.Dense(10, activation=tf.keras.activations.relu, name=\"hidden1\")(input2)\n",
    "h22 = tf.keras.layers.Dense(10, activation=tf.keras.activations.relu, name=\"hidden2\")(h21)\n",
    "h23 = tf.keras.layers.Dense(10, activation=tf.keras.activations.relu, name=\"hidden3\")(h22)\n",
    "p_val = tf.keras.layers.Dense(1, activation=tf.keras.activations.sigmoid, name=\"p_val\")(h23)\n",
    "out2 = tfp.layers.DistributionLambda(lambda t: tfp.distributions.Bernoulli(probs=t,  dtype=tf.float64), name=\"output\")(p_val)\n",
    "\n",
    "model2 = tf.keras.Model(inputs=input2, outputs=out2, name=\"IonosphereNNMLEwDistr\")\n",
    "\n",
    "model2.compile(optimizer=tf.optimizers.Adam(learning_rate=0.001), loss=expectNLL)\n",
    "print(model2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8a9c5a6fa0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(x, y, epochs=50, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95       225\n",
      "           1       0.92      0.90      0.91       126\n",
      "\n",
      "    accuracy                           0.93       351\n",
      "   macro avg       0.93      0.93      0.93       351\n",
      "weighted avg       0.93      0.93      0.93       351\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "yhat3 = model2.predict(x)\n",
    "\n",
    "def labelmaker(prob):\n",
    "    if prob > 0.4:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "yhat3 = np.apply_along_axis(labelmaker, 1, yhat3)\n",
    "print(classification_report(y.flatten(), yhat3.flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "348/351 [============================>.] - ETA: 0s0.0\n"
     ]
    }
   ],
   "source": [
    "la_model2 = LaplaceApproximation(model2)\n",
    "la_model2.fit([x,y])\n",
    "la_model2.set_std(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.91      0.92       225\n",
      "           1       0.85      0.87      0.86       126\n",
      "\n",
      "    accuracy                           0.90       351\n",
      "   macro avg       0.89      0.89      0.89       351\n",
      "weighted avg       0.90      0.90      0.90       351\n",
      "\n"
     ]
    }
   ],
   "source": [
    "yhat3 = la_model2.predict(x)\n",
    "\n",
    "def labelmaker(prob):\n",
    "    if prob > 0.4:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "yhat3 = np.apply_along_axis(labelmaker, 1, yhat3)\n",
    "print(classification_report(y.flatten(), yhat3.flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epistemic Uncertainty 0.17253219\n"
     ]
    }
   ],
   "source": [
    "y_dist2 = la_model2(x)\n",
    "\n",
    "means = y_dist2.mean().numpy()\n",
    "\n",
    "print('Epistemic Uncertainty', means.var())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-2.6",
   "language": "python",
   "name": "tf-2.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
