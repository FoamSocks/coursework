/var/spool/slurm/job48594387/slurm_script: line 16: module: command not found
Fri Aug 11 08:56:06 2023       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 530.30.02              Driver Version: 530.30.02    CUDA Version: 12.1     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                  Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf            Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA RTX A6000                On | 00000000:83:00.0 Off |                  Off |
| 30%   26C    P8               20W / 300W|      1MiB / 49140MiB |      0%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
|   1  NVIDIA RTX A6000                On | 00000000:84:00.0 Off |                  Off |
| 30%   26C    P8               28W / 300W|      1MiB / 49140MiB |      0%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
|   2  NVIDIA RTX A6000                On | 00000000:C3:00.0 Off |                  Off |
| 30%   25C    P8               26W / 300W|      1MiB / 49140MiB |      0%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
|   3  NVIDIA RTX A6000                On | 00000000:C4:00.0 Off |                  Off |
| 30%   26C    P8               24W / 300W|      1MiB / 49140MiB |      0%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|  No running processes found                                                           |
+---------------------------------------------------------------------------------------+
PyTorch Version: 2.0.1
GPUs available: 4
CPUs available: 128
Using CUDA
Namespace(model_dir='../models/mobilenetv2_48594387_2023-08-11_08-56-07/', test_dir='/data/cs4321/HW1/test', train_dir='/data/cs4321/HW1/train', val_dir='/data/cs4321/HW1/validation', model_type='mobilenetv2', num_classes=8, num_epochs=40, batch_size=8, fixed=False, unfreeze=12, optimizer='sgd', callback_list='checkpoint, csv_log', base_learning_rate=0.001, nodes=1, gpus=1, world_size=1)
model_dir : ../models/mobilenetv2_48594387_2023-08-11_08-56-07/
test_dir : /data/cs4321/HW1/test
train_dir : /data/cs4321/HW1/train
val_dir : /data/cs4321/HW1/validation
model_type : mobilenetv2
num_classes : 8
num_epochs : 40
batch_size : 8
fixed : False
unfreeze : 12
optimizer : sgd
callback_list : checkpoint, csv_log
base_learning_rate : 0.001
nodes : 1
gpus : 1
world_size : 1
Loaded 6400 images under train
Loaded 1600 images under validation
Loaded 800 images under test
Created all datasets
Classes: 
['CoastalCliffs', 'CoastalRocky', 'CoastalWaterWay', 'Dunes', 'ManMadeStructures', 'SaltMarshes', 'SandyBeaches', 'TidalFlats']
Rank: 0
Creating fixed-feature model: mobilenetv2
=============================================================================================================================
Layer (type (var_name))                       Input Shape          Output Shape         Param #              Trainable
=============================================================================================================================
MobileNetV2 (MobileNetV2)                     [8, 3, 224, 224]     [8, 8]               --                   Partial
├─Sequential (features)                       [8, 3, 224, 224]     [8, 1280, 7, 7]      --                   Partial
│    └─Conv2dNormActivation (0)               [8, 3, 224, 224]     [8, 32, 112, 112]    --                   False
│    │    └─Conv2d (0)                        [8, 3, 224, 224]     [8, 32, 112, 112]    (864)                False
│    │    └─BatchNorm2d (1)                   [8, 32, 112, 112]    [8, 32, 112, 112]    (64)                 False
│    │    └─ReLU6 (2)                         [8, 32, 112, 112]    [8, 32, 112, 112]    --                   --
│    └─InvertedResidual (1)                   [8, 32, 112, 112]    [8, 16, 112, 112]    --                   False
│    │    └─Sequential (conv)                 [8, 32, 112, 112]    [8, 16, 112, 112]    (896)                False
│    └─InvertedResidual (2)                   [8, 16, 112, 112]    [8, 24, 56, 56]      --                   False
│    │    └─Sequential (conv)                 [8, 16, 112, 112]    [8, 24, 56, 56]      (5,136)              False
│    └─InvertedResidual (3)                   [8, 24, 56, 56]      [8, 24, 56, 56]      --                   False
│    │    └─Sequential (conv)                 [8, 24, 56, 56]      [8, 24, 56, 56]      (8,832)              False
│    └─InvertedResidual (4)                   [8, 24, 56, 56]      [8, 32, 28, 28]      --                   False
│    │    └─Sequential (conv)                 [8, 24, 56, 56]      [8, 32, 28, 28]      (10,000)             False
│    └─InvertedResidual (5)                   [8, 32, 28, 28]      [8, 32, 28, 28]      --                   False
│    │    └─Sequential (conv)                 [8, 32, 28, 28]      [8, 32, 28, 28]      (14,848)             False
│    └─InvertedResidual (6)                   [8, 32, 28, 28]      [8, 32, 28, 28]      --                   False
│    │    └─Sequential (conv)                 [8, 32, 28, 28]      [8, 32, 28, 28]      (14,848)             False
│    └─InvertedResidual (7)                   [8, 32, 28, 28]      [8, 64, 14, 14]      --                   True
│    │    └─Sequential (conv)                 [8, 32, 28, 28]      [8, 64, 14, 14]      21,056               True
│    └─InvertedResidual (8)                   [8, 64, 14, 14]      [8, 64, 14, 14]      --                   False
│    │    └─Sequential (conv)                 [8, 64, 14, 14]      [8, 64, 14, 14]      (54,272)             False
│    └─InvertedResidual (9)                   [8, 64, 14, 14]      [8, 64, 14, 14]      --                   False
│    │    └─Sequential (conv)                 [8, 64, 14, 14]      [8, 64, 14, 14]      (54,272)             False
│    └─InvertedResidual (10)                  [8, 64, 14, 14]      [8, 64, 14, 14]      --                   False
│    │    └─Sequential (conv)                 [8, 64, 14, 14]      [8, 64, 14, 14]      (54,272)             False
│    └─InvertedResidual (11)                  [8, 64, 14, 14]      [8, 96, 14, 14]      --                   False
│    │    └─Sequential (conv)                 [8, 64, 14, 14]      [8, 96, 14, 14]      (66,624)             False
│    └─InvertedResidual (12)                  [8, 96, 14, 14]      [8, 96, 14, 14]      --                   False
│    │    └─Sequential (conv)                 [8, 96, 14, 14]      [8, 96, 14, 14]      (118,272)            False
│    └─InvertedResidual (13)                  [8, 96, 14, 14]      [8, 96, 14, 14]      --                   False
│    │    └─Sequential (conv)                 [8, 96, 14, 14]      [8, 96, 14, 14]      (118,272)            False
│    └─InvertedResidual (14)                  [8, 96, 14, 14]      [8, 160, 7, 7]       --                   False
│    │    └─Sequential (conv)                 [8, 96, 14, 14]      [8, 160, 7, 7]       (155,264)            False
│    └─InvertedResidual (15)                  [8, 160, 7, 7]       [8, 160, 7, 7]       --                   False
│    │    └─Sequential (conv)                 [8, 160, 7, 7]       [8, 160, 7, 7]       (320,000)            False
│    └─InvertedResidual (16)                  [8, 160, 7, 7]       [8, 160, 7, 7]       --                   False
│    │    └─Sequential (conv)                 [8, 160, 7, 7]       [8, 160, 7, 7]       (320,000)            False
│    └─InvertedResidual (17)                  [8, 160, 7, 7]       [8, 320, 7, 7]       --                   False
│    │    └─Sequential (conv)                 [8, 160, 7, 7]       [8, 320, 7, 7]       (473,920)            False
│    └─Conv2dNormActivation (18)              [8, 320, 7, 7]       [8, 1280, 7, 7]      --                   False
│    │    └─Conv2d (0)                        [8, 320, 7, 7]       [8, 1280, 7, 7]      (409,600)            False
│    │    └─BatchNorm2d (1)                   [8, 1280, 7, 7]      [8, 1280, 7, 7]      (2,560)              False
│    │    └─ReLU6 (2)                         [8, 1280, 7, 7]      [8, 1280, 7, 7]      --                   --
├─Sequential (classifier)                     [8, 1280]            [8, 8]               --                   True
│    └─Dropout (0)                            [8, 1280]            [8, 1280]            --                   --
│    └─Linear (1)                             [8, 1280]            [8, 8]               10,248               True
=============================================================================================================================
Total params: 2,234,120
Trainable params: 31,304
Non-trainable params: 2,202,816
Total mult-adds (Units.GIGABYTES): 2.40
=============================================================================================================================
Input size (MB): 4.82
Forward/backward pass size (MB): 854.80
Params size (MB): 8.94
Estimated Total Size (MB): 868.55
=============================================================================================================================
Epoch [1/40] - Train Loss: 1.4506, Train Accuracy: 0.5475, Val Loss: 0.9554, Val Accuracy: 0.7338
Test Loss: 0.9180, Test Accuracy: 0.7425
Epoch [2/40] - Train Loss: 1.0905, Train Accuracy: 0.6420, Val Loss: 0.7822, Val Accuracy: 0.7619
Test Loss: 0.7324, Test Accuracy: 0.7750
Epoch [3/40] - Train Loss: 1.0015, Train Accuracy: 0.6648, Val Loss: 0.7113, Val Accuracy: 0.7825
Test Loss: 0.6682, Test Accuracy: 0.7950
Epoch [4/40] - Train Loss: 0.9204, Train Accuracy: 0.6856, Val Loss: 0.6688, Val Accuracy: 0.7850
Test Loss: 0.6164, Test Accuracy: 0.7963
Epoch [5/40] - Train Loss: 0.8830, Train Accuracy: 0.6994, Val Loss: 0.6214, Val Accuracy: 0.8137
Test Loss: 0.5676, Test Accuracy: 0.8187
Epoch [6/40] - Train Loss: 0.8634, Train Accuracy: 0.7047, Val Loss: 0.6134, Val Accuracy: 0.8081
Test Loss: 0.5377, Test Accuracy: 0.8275
Epoch [7/40] - Train Loss: 0.8409, Train Accuracy: 0.7161, Val Loss: 0.5694, Val Accuracy: 0.8206
Test Loss: 0.5156, Test Accuracy: 0.8237
Epoch [8/40] - Train Loss: 0.8172, Train Accuracy: 0.7245, Val Loss: 0.5641, Val Accuracy: 0.8194
Test Loss: 0.5202, Test Accuracy: 0.8200
Epoch [9/40] - Train Loss: 0.7999, Train Accuracy: 0.7291, Val Loss: 0.5536, Val Accuracy: 0.8263
Test Loss: 0.5063, Test Accuracy: 0.8213
Epoch [10/40] - Train Loss: 0.7891, Train Accuracy: 0.7302, Val Loss: 0.5445, Val Accuracy: 0.8300
Test Loss: 0.5085, Test Accuracy: 0.8325
Epoch [11/40] - Train Loss: 0.7721, Train Accuracy: 0.7302, Val Loss: 0.5200, Val Accuracy: 0.8363
Test Loss: 0.4650, Test Accuracy: 0.8525
Epoch [12/40] - Train Loss: 0.7620, Train Accuracy: 0.7419, Val Loss: 0.5151, Val Accuracy: 0.8419
Test Loss: 0.4555, Test Accuracy: 0.8387
Epoch [13/40] - Train Loss: 0.7600, Train Accuracy: 0.7398, Val Loss: 0.4908, Val Accuracy: 0.8456
Test Loss: 0.4300, Test Accuracy: 0.8588
Epoch [14/40] - Train Loss: 0.7525, Train Accuracy: 0.7458, Val Loss: 0.4924, Val Accuracy: 0.8444
Test Loss: 0.4320, Test Accuracy: 0.8675
Epoch [15/40] - Train Loss: 0.7545, Train Accuracy: 0.7427, Val Loss: 0.4911, Val Accuracy: 0.8469
Test Loss: 0.4548, Test Accuracy: 0.8400
Epoch [16/40] - Train Loss: 0.7505, Train Accuracy: 0.7503, Val Loss: 0.4911, Val Accuracy: 0.8456
Test Loss: 0.4512, Test Accuracy: 0.8425
Epoch [17/40] - Train Loss: 0.7239, Train Accuracy: 0.7580, Val Loss: 0.4851, Val Accuracy: 0.8425
Test Loss: 0.4263, Test Accuracy: 0.8662
Epoch [18/40] - Train Loss: 0.7437, Train Accuracy: 0.7408, Val Loss: 0.4835, Val Accuracy: 0.8469
Test Loss: 0.4194, Test Accuracy: 0.8575
Epoch [19/40] - Train Loss: 0.7210, Train Accuracy: 0.7569, Val Loss: 0.4906, Val Accuracy: 0.8500
Test Loss: 0.4000, Test Accuracy: 0.8712
Epoch [20/40] - Train Loss: 0.7130, Train Accuracy: 0.7570, Val Loss: 0.4783, Val Accuracy: 0.8500
Test Loss: 0.3924, Test Accuracy: 0.8688
Epoch [21/40] - Train Loss: 0.7201, Train Accuracy: 0.7514, Val Loss: 0.4770, Val Accuracy: 0.8481
Test Loss: 0.4207, Test Accuracy: 0.8675
Epoch [22/40] - Train Loss: 0.7147, Train Accuracy: 0.7559, Val Loss: 0.4639, Val Accuracy: 0.8494
Test Loss: 0.4142, Test Accuracy: 0.8588
Epoch [23/40] - Train Loss: 0.6963, Train Accuracy: 0.7609, Val Loss: 0.4528, Val Accuracy: 0.8550
Test Loss: 0.3757, Test Accuracy: 0.8762
Epoch [24/40] - Train Loss: 0.7046, Train Accuracy: 0.7636, Val Loss: 0.4564, Val Accuracy: 0.8525
Test Loss: 0.4132, Test Accuracy: 0.8612
Epoch [25/40] - Train Loss: 0.7193, Train Accuracy: 0.7542, Val Loss: 0.4678, Val Accuracy: 0.8588
Test Loss: 0.4068, Test Accuracy: 0.8700
Epoch [26/40] - Train Loss: 0.6893, Train Accuracy: 0.7638, Val Loss: 0.4612, Val Accuracy: 0.8575
Test Loss: 0.3850, Test Accuracy: 0.8662
Epoch [27/40] - Train Loss: 0.6796, Train Accuracy: 0.7727, Val Loss: 0.4634, Val Accuracy: 0.8569
Test Loss: 0.3722, Test Accuracy: 0.8775
Epoch [28/40] - Train Loss: 0.6935, Train Accuracy: 0.7636, Val Loss: 0.4379, Val Accuracy: 0.8662
Test Loss: 0.3580, Test Accuracy: 0.8812
Epoch [29/40] - Train Loss: 0.6815, Train Accuracy: 0.7684, Val Loss: 0.4456, Val Accuracy: 0.8638
Test Loss: 0.3809, Test Accuracy: 0.8800
Epoch [30/40] - Train Loss: 0.6641, Train Accuracy: 0.7800, Val Loss: 0.4303, Val Accuracy: 0.8656
Test Loss: 0.3672, Test Accuracy: 0.8875
Epoch [31/40] - Train Loss: 0.6853, Train Accuracy: 0.7692, Val Loss: 0.4360, Val Accuracy: 0.8706
Test Loss: 0.3818, Test Accuracy: 0.8725
Epoch [32/40] - Train Loss: 0.6835, Train Accuracy: 0.7669, Val Loss: 0.4435, Val Accuracy: 0.8700
Test Loss: 0.3868, Test Accuracy: 0.8800
Epoch [33/40] - Train Loss: 0.6692, Train Accuracy: 0.7692, Val Loss: 0.4169, Val Accuracy: 0.8731
Test Loss: 0.3549, Test Accuracy: 0.8812
Epoch [34/40] - Train Loss: 0.6689, Train Accuracy: 0.7764, Val Loss: 0.4230, Val Accuracy: 0.8581
Test Loss: 0.3818, Test Accuracy: 0.8638
Epoch [35/40] - Train Loss: 0.6720, Train Accuracy: 0.7761, Val Loss: 0.4329, Val Accuracy: 0.8575
Test Loss: 0.3725, Test Accuracy: 0.8800
Epoch [36/40] - Train Loss: 0.6567, Train Accuracy: 0.7745, Val Loss: 0.4149, Val Accuracy: 0.8669
Test Loss: 0.3571, Test Accuracy: 0.8788
Epoch [37/40] - Train Loss: 0.6657, Train Accuracy: 0.7731, Val Loss: 0.4143, Val Accuracy: 0.8731
Test Loss: 0.3549, Test Accuracy: 0.8825
Epoch [38/40] - Train Loss: 0.6635, Train Accuracy: 0.7698, Val Loss: 0.4233, Val Accuracy: 0.8731
Test Loss: 0.3663, Test Accuracy: 0.8788
Epoch [39/40] - Train Loss: 0.6668, Train Accuracy: 0.7706, Val Loss: 0.4180, Val Accuracy: 0.8694
Test Loss: 0.3521, Test Accuracy: 0.8838
Epoch [40/40] - Train Loss: 0.6544, Train Accuracy: 0.7756, Val Loss: 0.4182, Val Accuracy: 0.8650
Test Loss: 0.3625, Test Accuracy: 0.8700
Start time: 2023-08-11 08:56:08.677906
End time: 2023-08-11 09:05:38.486126
Total time: 0:09:29.808220
