/var/spool/slurm/job48594385/slurm_script: line 16: module: command not found
Fri Aug 11 08:54:41 2023       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 530.30.02              Driver Version: 530.30.02    CUDA Version: 12.1     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                  Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf            Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA RTX A6000                On | 00000000:03:00.0 Off |                  Off |
| 30%   31C    P8               27W / 300W|      1MiB / 49140MiB |      0%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
|   1  NVIDIA RTX A6000                On | 00000000:04:00.0 Off |                  Off |
| 30%   30C    P8               31W / 300W|      1MiB / 49140MiB |      0%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
|   2  NVIDIA RTX A6000                On | 00000000:43:00.0 Off |                  Off |
| 30%   32C    P8               38W / 300W|      1MiB / 49140MiB |      0%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
|   3  NVIDIA RTX A6000                On | 00000000:44:00.0 Off |                  Off |
| 30%   32C    P8               31W / 300W|      1MiB / 49140MiB |      0%      Default |
|                                         |                      |                  N/A |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|  No running processes found                                                           |
+---------------------------------------------------------------------------------------+
PyTorch Version: 2.0.1
GPUs available: 4
CPUs available: 128
Using CUDA
Namespace(model_dir='../models/resnet50_48594385_2023-08-11_08-54-42/', test_dir='/data/cs4321/HW1/test', train_dir='/data/cs4321/HW1/train', val_dir='/data/cs4321/HW1/validation', model_type='resnet50', num_classes=8, num_epochs=40, batch_size=8, fixed=False, unfreeze=3, optimizer='sgd', callback_list='checkpoint, csv_log', base_learning_rate=0.001, nodes=1, gpus=1, world_size=1)
model_dir : ../models/resnet50_48594385_2023-08-11_08-54-42/
test_dir : /data/cs4321/HW1/test
train_dir : /data/cs4321/HW1/train
val_dir : /data/cs4321/HW1/validation
model_type : resnet50
num_classes : 8
num_epochs : 40
batch_size : 8
fixed : False
unfreeze : 3
optimizer : sgd
callback_list : checkpoint, csv_log
base_learning_rate : 0.001
nodes : 1
gpus : 1
world_size : 1
Loaded 6400 images under train
Loaded 1600 images under validation
Loaded 800 images under test
Created all datasets
Classes: 
['CoastalCliffs', 'CoastalRocky', 'CoastalWaterWay', 'Dunes', 'ManMadeStructures', 'SaltMarshes', 'SandyBeaches', 'TidalFlats']
Rank: 0
Creating fixed-feature model: resnet50
========================================================================================================================
Layer (type (var_name))                  Input Shape          Output Shape         Param #              Trainable
========================================================================================================================
ResNet (ResNet)                          [8, 3, 224, 224]     [8, 8]               --                   Partial
├─Conv2d (conv1)                         [8, 3, 224, 224]     [8, 64, 112, 112]    (9,408)              False
├─BatchNorm2d (bn1)                      [8, 64, 112, 112]    [8, 64, 112, 112]    (128)                False
├─ReLU (relu)                            [8, 64, 112, 112]    [8, 64, 112, 112]    --                   --
├─MaxPool2d (maxpool)                    [8, 64, 112, 112]    [8, 64, 56, 56]      --                   --
├─Sequential (layer1)                    [8, 64, 56, 56]      [8, 256, 56, 56]     --                   False
│    └─Bottleneck (0)                    [8, 64, 56, 56]      [8, 256, 56, 56]     --                   False
│    │    └─Conv2d (conv1)               [8, 64, 56, 56]      [8, 64, 56, 56]      (4,096)              False
│    │    └─BatchNorm2d (bn1)            [8, 64, 56, 56]      [8, 64, 56, 56]      (128)                False
│    │    └─ReLU (relu)                  [8, 64, 56, 56]      [8, 64, 56, 56]      --                   --
│    │    └─Conv2d (conv2)               [8, 64, 56, 56]      [8, 64, 56, 56]      (36,864)             False
│    │    └─BatchNorm2d (bn2)            [8, 64, 56, 56]      [8, 64, 56, 56]      (128)                False
│    │    └─ReLU (relu)                  [8, 64, 56, 56]      [8, 64, 56, 56]      --                   --
│    │    └─Conv2d (conv3)               [8, 64, 56, 56]      [8, 256, 56, 56]     (16,384)             False
│    │    └─BatchNorm2d (bn3)            [8, 256, 56, 56]     [8, 256, 56, 56]     (512)                False
│    │    └─Sequential (downsample)      [8, 64, 56, 56]      [8, 256, 56, 56]     (16,896)             False
│    │    └─ReLU (relu)                  [8, 256, 56, 56]     [8, 256, 56, 56]     --                   --
│    └─Bottleneck (1)                    [8, 256, 56, 56]     [8, 256, 56, 56]     --                   False
│    │    └─Conv2d (conv1)               [8, 256, 56, 56]     [8, 64, 56, 56]      (16,384)             False
│    │    └─BatchNorm2d (bn1)            [8, 64, 56, 56]      [8, 64, 56, 56]      (128)                False
│    │    └─ReLU (relu)                  [8, 64, 56, 56]      [8, 64, 56, 56]      --                   --
│    │    └─Conv2d (conv2)               [8, 64, 56, 56]      [8, 64, 56, 56]      (36,864)             False
│    │    └─BatchNorm2d (bn2)            [8, 64, 56, 56]      [8, 64, 56, 56]      (128)                False
│    │    └─ReLU (relu)                  [8, 64, 56, 56]      [8, 64, 56, 56]      --                   --
│    │    └─Conv2d (conv3)               [8, 64, 56, 56]      [8, 256, 56, 56]     (16,384)             False
│    │    └─BatchNorm2d (bn3)            [8, 256, 56, 56]     [8, 256, 56, 56]     (512)                False
│    │    └─ReLU (relu)                  [8, 256, 56, 56]     [8, 256, 56, 56]     --                   --
│    └─Bottleneck (2)                    [8, 256, 56, 56]     [8, 256, 56, 56]     --                   False
│    │    └─Conv2d (conv1)               [8, 256, 56, 56]     [8, 64, 56, 56]      (16,384)             False
│    │    └─BatchNorm2d (bn1)            [8, 64, 56, 56]      [8, 64, 56, 56]      (128)                False
│    │    └─ReLU (relu)                  [8, 64, 56, 56]      [8, 64, 56, 56]      --                   --
│    │    └─Conv2d (conv2)               [8, 64, 56, 56]      [8, 64, 56, 56]      (36,864)             False
│    │    └─BatchNorm2d (bn2)            [8, 64, 56, 56]      [8, 64, 56, 56]      (128)                False
│    │    └─ReLU (relu)                  [8, 64, 56, 56]      [8, 64, 56, 56]      --                   --
│    │    └─Conv2d (conv3)               [8, 64, 56, 56]      [8, 256, 56, 56]     (16,384)             False
│    │    └─BatchNorm2d (bn3)            [8, 256, 56, 56]     [8, 256, 56, 56]     (512)                False
│    │    └─ReLU (relu)                  [8, 256, 56, 56]     [8, 256, 56, 56]     --                   --
├─Sequential (layer2)                    [8, 256, 56, 56]     [8, 512, 28, 28]     --                   True
│    └─Bottleneck (0)                    [8, 256, 56, 56]     [8, 512, 28, 28]     --                   True
│    │    └─Conv2d (conv1)               [8, 256, 56, 56]     [8, 128, 56, 56]     32,768               True
│    │    └─BatchNorm2d (bn1)            [8, 128, 56, 56]     [8, 128, 56, 56]     256                  True
│    │    └─ReLU (relu)                  [8, 128, 56, 56]     [8, 128, 56, 56]     --                   --
│    │    └─Conv2d (conv2)               [8, 128, 56, 56]     [8, 128, 28, 28]     147,456              True
│    │    └─BatchNorm2d (bn2)            [8, 128, 28, 28]     [8, 128, 28, 28]     256                  True
│    │    └─ReLU (relu)                  [8, 128, 28, 28]     [8, 128, 28, 28]     --                   --
│    │    └─Conv2d (conv3)               [8, 128, 28, 28]     [8, 512, 28, 28]     65,536               True
│    │    └─BatchNorm2d (bn3)            [8, 512, 28, 28]     [8, 512, 28, 28]     1,024                True
│    │    └─Sequential (downsample)      [8, 256, 56, 56]     [8, 512, 28, 28]     132,096              True
│    │    └─ReLU (relu)                  [8, 512, 28, 28]     [8, 512, 28, 28]     --                   --
│    └─Bottleneck (1)                    [8, 512, 28, 28]     [8, 512, 28, 28]     --                   True
│    │    └─Conv2d (conv1)               [8, 512, 28, 28]     [8, 128, 28, 28]     65,536               True
│    │    └─BatchNorm2d (bn1)            [8, 128, 28, 28]     [8, 128, 28, 28]     256                  True
│    │    └─ReLU (relu)                  [8, 128, 28, 28]     [8, 128, 28, 28]     --                   --
│    │    └─Conv2d (conv2)               [8, 128, 28, 28]     [8, 128, 28, 28]     147,456              True
│    │    └─BatchNorm2d (bn2)            [8, 128, 28, 28]     [8, 128, 28, 28]     256                  True
│    │    └─ReLU (relu)                  [8, 128, 28, 28]     [8, 128, 28, 28]     --                   --
│    │    └─Conv2d (conv3)               [8, 128, 28, 28]     [8, 512, 28, 28]     65,536               True
│    │    └─BatchNorm2d (bn3)            [8, 512, 28, 28]     [8, 512, 28, 28]     1,024                True
│    │    └─ReLU (relu)                  [8, 512, 28, 28]     [8, 512, 28, 28]     --                   --
│    └─Bottleneck (2)                    [8, 512, 28, 28]     [8, 512, 28, 28]     --                   True
│    │    └─Conv2d (conv1)               [8, 512, 28, 28]     [8, 128, 28, 28]     65,536               True
│    │    └─BatchNorm2d (bn1)            [8, 128, 28, 28]     [8, 128, 28, 28]     256                  True
│    │    └─ReLU (relu)                  [8, 128, 28, 28]     [8, 128, 28, 28]     --                   --
│    │    └─Conv2d (conv2)               [8, 128, 28, 28]     [8, 128, 28, 28]     147,456              True
│    │    └─BatchNorm2d (bn2)            [8, 128, 28, 28]     [8, 128, 28, 28]     256                  True
│    │    └─ReLU (relu)                  [8, 128, 28, 28]     [8, 128, 28, 28]     --                   --
│    │    └─Conv2d (conv3)               [8, 128, 28, 28]     [8, 512, 28, 28]     65,536               True
│    │    └─BatchNorm2d (bn3)            [8, 512, 28, 28]     [8, 512, 28, 28]     1,024                True
│    │    └─ReLU (relu)                  [8, 512, 28, 28]     [8, 512, 28, 28]     --                   --
│    └─Bottleneck (3)                    [8, 512, 28, 28]     [8, 512, 28, 28]     --                   True
│    │    └─Conv2d (conv1)               [8, 512, 28, 28]     [8, 128, 28, 28]     65,536               True
│    │    └─BatchNorm2d (bn1)            [8, 128, 28, 28]     [8, 128, 28, 28]     256                  True
│    │    └─ReLU (relu)                  [8, 128, 28, 28]     [8, 128, 28, 28]     --                   --
│    │    └─Conv2d (conv2)               [8, 128, 28, 28]     [8, 128, 28, 28]     147,456              True
│    │    └─BatchNorm2d (bn2)            [8, 128, 28, 28]     [8, 128, 28, 28]     256                  True
│    │    └─ReLU (relu)                  [8, 128, 28, 28]     [8, 128, 28, 28]     --                   --
│    │    └─Conv2d (conv3)               [8, 128, 28, 28]     [8, 512, 28, 28]     65,536               True
│    │    └─BatchNorm2d (bn3)            [8, 512, 28, 28]     [8, 512, 28, 28]     1,024                True
│    │    └─ReLU (relu)                  [8, 512, 28, 28]     [8, 512, 28, 28]     --                   --
├─Sequential (layer3)                    [8, 512, 28, 28]     [8, 1024, 14, 14]    --                   True
│    └─Bottleneck (0)                    [8, 512, 28, 28]     [8, 1024, 14, 14]    --                   True
│    │    └─Conv2d (conv1)               [8, 512, 28, 28]     [8, 256, 28, 28]     131,072              True
│    │    └─BatchNorm2d (bn1)            [8, 256, 28, 28]     [8, 256, 28, 28]     512                  True
│    │    └─ReLU (relu)                  [8, 256, 28, 28]     [8, 256, 28, 28]     --                   --
│    │    └─Conv2d (conv2)               [8, 256, 28, 28]     [8, 256, 14, 14]     589,824              True
│    │    └─BatchNorm2d (bn2)            [8, 256, 14, 14]     [8, 256, 14, 14]     512                  True
│    │    └─ReLU (relu)                  [8, 256, 14, 14]     [8, 256, 14, 14]     --                   --
│    │    └─Conv2d (conv3)               [8, 256, 14, 14]     [8, 1024, 14, 14]    262,144              True
│    │    └─BatchNorm2d (bn3)            [8, 1024, 14, 14]    [8, 1024, 14, 14]    2,048                True
│    │    └─Sequential (downsample)      [8, 512, 28, 28]     [8, 1024, 14, 14]    526,336              True
│    │    └─ReLU (relu)                  [8, 1024, 14, 14]    [8, 1024, 14, 14]    --                   --
│    └─Bottleneck (1)                    [8, 1024, 14, 14]    [8, 1024, 14, 14]    --                   True
│    │    └─Conv2d (conv1)               [8, 1024, 14, 14]    [8, 256, 14, 14]     262,144              True
│    │    └─BatchNorm2d (bn1)            [8, 256, 14, 14]     [8, 256, 14, 14]     512                  True
│    │    └─ReLU (relu)                  [8, 256, 14, 14]     [8, 256, 14, 14]     --                   --
│    │    └─Conv2d (conv2)               [8, 256, 14, 14]     [8, 256, 14, 14]     589,824              True
│    │    └─BatchNorm2d (bn2)            [8, 256, 14, 14]     [8, 256, 14, 14]     512                  True
│    │    └─ReLU (relu)                  [8, 256, 14, 14]     [8, 256, 14, 14]     --                   --
│    │    └─Conv2d (conv3)               [8, 256, 14, 14]     [8, 1024, 14, 14]    262,144              True
│    │    └─BatchNorm2d (bn3)            [8, 1024, 14, 14]    [8, 1024, 14, 14]    2,048                True
│    │    └─ReLU (relu)                  [8, 1024, 14, 14]    [8, 1024, 14, 14]    --                   --
│    └─Bottleneck (2)                    [8, 1024, 14, 14]    [8, 1024, 14, 14]    --                   True
│    │    └─Conv2d (conv1)               [8, 1024, 14, 14]    [8, 256, 14, 14]     262,144              True
│    │    └─BatchNorm2d (bn1)            [8, 256, 14, 14]     [8, 256, 14, 14]     512                  True
│    │    └─ReLU (relu)                  [8, 256, 14, 14]     [8, 256, 14, 14]     --                   --
│    │    └─Conv2d (conv2)               [8, 256, 14, 14]     [8, 256, 14, 14]     589,824              True
│    │    └─BatchNorm2d (bn2)            [8, 256, 14, 14]     [8, 256, 14, 14]     512                  True
│    │    └─ReLU (relu)                  [8, 256, 14, 14]     [8, 256, 14, 14]     --                   --
│    │    └─Conv2d (conv3)               [8, 256, 14, 14]     [8, 1024, 14, 14]    262,144              True
│    │    └─BatchNorm2d (bn3)            [8, 1024, 14, 14]    [8, 1024, 14, 14]    2,048                True
│    │    └─ReLU (relu)                  [8, 1024, 14, 14]    [8, 1024, 14, 14]    --                   --
│    └─Bottleneck (3)                    [8, 1024, 14, 14]    [8, 1024, 14, 14]    --                   True
│    │    └─Conv2d (conv1)               [8, 1024, 14, 14]    [8, 256, 14, 14]     262,144              True
│    │    └─BatchNorm2d (bn1)            [8, 256, 14, 14]     [8, 256, 14, 14]     512                  True
│    │    └─ReLU (relu)                  [8, 256, 14, 14]     [8, 256, 14, 14]     --                   --
│    │    └─Conv2d (conv2)               [8, 256, 14, 14]     [8, 256, 14, 14]     589,824              True
│    │    └─BatchNorm2d (bn2)            [8, 256, 14, 14]     [8, 256, 14, 14]     512                  True
│    │    └─ReLU (relu)                  [8, 256, 14, 14]     [8, 256, 14, 14]     --                   --
│    │    └─Conv2d (conv3)               [8, 256, 14, 14]     [8, 1024, 14, 14]    262,144              True
│    │    └─BatchNorm2d (bn3)            [8, 1024, 14, 14]    [8, 1024, 14, 14]    2,048                True
│    │    └─ReLU (relu)                  [8, 1024, 14, 14]    [8, 1024, 14, 14]    --                   --
│    └─Bottleneck (4)                    [8, 1024, 14, 14]    [8, 1024, 14, 14]    --                   True
│    │    └─Conv2d (conv1)               [8, 1024, 14, 14]    [8, 256, 14, 14]     262,144              True
│    │    └─BatchNorm2d (bn1)            [8, 256, 14, 14]     [8, 256, 14, 14]     512                  True
│    │    └─ReLU (relu)                  [8, 256, 14, 14]     [8, 256, 14, 14]     --                   --
│    │    └─Conv2d (conv2)               [8, 256, 14, 14]     [8, 256, 14, 14]     589,824              True
│    │    └─BatchNorm2d (bn2)            [8, 256, 14, 14]     [8, 256, 14, 14]     512                  True
│    │    └─ReLU (relu)                  [8, 256, 14, 14]     [8, 256, 14, 14]     --                   --
│    │    └─Conv2d (conv3)               [8, 256, 14, 14]     [8, 1024, 14, 14]    262,144              True
│    │    └─BatchNorm2d (bn3)            [8, 1024, 14, 14]    [8, 1024, 14, 14]    2,048                True
│    │    └─ReLU (relu)                  [8, 1024, 14, 14]    [8, 1024, 14, 14]    --                   --
│    └─Bottleneck (5)                    [8, 1024, 14, 14]    [8, 1024, 14, 14]    --                   True
│    │    └─Conv2d (conv1)               [8, 1024, 14, 14]    [8, 256, 14, 14]     262,144              True
│    │    └─BatchNorm2d (bn1)            [8, 256, 14, 14]     [8, 256, 14, 14]     512                  True
│    │    └─ReLU (relu)                  [8, 256, 14, 14]     [8, 256, 14, 14]     --                   --
│    │    └─Conv2d (conv2)               [8, 256, 14, 14]     [8, 256, 14, 14]     589,824              True
│    │    └─BatchNorm2d (bn2)            [8, 256, 14, 14]     [8, 256, 14, 14]     512                  True
│    │    └─ReLU (relu)                  [8, 256, 14, 14]     [8, 256, 14, 14]     --                   --
│    │    └─Conv2d (conv3)               [8, 256, 14, 14]     [8, 1024, 14, 14]    262,144              True
│    │    └─BatchNorm2d (bn3)            [8, 1024, 14, 14]    [8, 1024, 14, 14]    2,048                True
│    │    └─ReLU (relu)                  [8, 1024, 14, 14]    [8, 1024, 14, 14]    --                   --
├─Sequential (layer4)                    [8, 1024, 14, 14]    [8, 2048, 7, 7]      --                   True
│    └─Bottleneck (0)                    [8, 1024, 14, 14]    [8, 2048, 7, 7]      --                   True
│    │    └─Conv2d (conv1)               [8, 1024, 14, 14]    [8, 512, 14, 14]     524,288              True
│    │    └─BatchNorm2d (bn1)            [8, 512, 14, 14]     [8, 512, 14, 14]     1,024                True
│    │    └─ReLU (relu)                  [8, 512, 14, 14]     [8, 512, 14, 14]     --                   --
│    │    └─Conv2d (conv2)               [8, 512, 14, 14]     [8, 512, 7, 7]       2,359,296            True
│    │    └─BatchNorm2d (bn2)            [8, 512, 7, 7]       [8, 512, 7, 7]       1,024                True
│    │    └─ReLU (relu)                  [8, 512, 7, 7]       [8, 512, 7, 7]       --                   --
│    │    └─Conv2d (conv3)               [8, 512, 7, 7]       [8, 2048, 7, 7]      1,048,576            True
│    │    └─BatchNorm2d (bn3)            [8, 2048, 7, 7]      [8, 2048, 7, 7]      4,096                True
│    │    └─Sequential (downsample)      [8, 1024, 14, 14]    [8, 2048, 7, 7]      2,101,248            True
│    │    └─ReLU (relu)                  [8, 2048, 7, 7]      [8, 2048, 7, 7]      --                   --
│    └─Bottleneck (1)                    [8, 2048, 7, 7]      [8, 2048, 7, 7]      --                   True
│    │    └─Conv2d (conv1)               [8, 2048, 7, 7]      [8, 512, 7, 7]       1,048,576            True
│    │    └─BatchNorm2d (bn1)            [8, 512, 7, 7]       [8, 512, 7, 7]       1,024                True
│    │    └─ReLU (relu)                  [8, 512, 7, 7]       [8, 512, 7, 7]       --                   --
│    │    └─Conv2d (conv2)               [8, 512, 7, 7]       [8, 512, 7, 7]       2,359,296            True
│    │    └─BatchNorm2d (bn2)            [8, 512, 7, 7]       [8, 512, 7, 7]       1,024                True
│    │    └─ReLU (relu)                  [8, 512, 7, 7]       [8, 512, 7, 7]       --                   --
│    │    └─Conv2d (conv3)               [8, 512, 7, 7]       [8, 2048, 7, 7]      1,048,576            True
│    │    └─BatchNorm2d (bn3)            [8, 2048, 7, 7]      [8, 2048, 7, 7]      4,096                True
│    │    └─ReLU (relu)                  [8, 2048, 7, 7]      [8, 2048, 7, 7]      --                   --
│    └─Bottleneck (2)                    [8, 2048, 7, 7]      [8, 2048, 7, 7]      --                   True
│    │    └─Conv2d (conv1)               [8, 2048, 7, 7]      [8, 512, 7, 7]       1,048,576            True
│    │    └─BatchNorm2d (bn1)            [8, 512, 7, 7]       [8, 512, 7, 7]       1,024                True
│    │    └─ReLU (relu)                  [8, 512, 7, 7]       [8, 512, 7, 7]       --                   --
│    │    └─Conv2d (conv2)               [8, 512, 7, 7]       [8, 512, 7, 7]       2,359,296            True
│    │    └─BatchNorm2d (bn2)            [8, 512, 7, 7]       [8, 512, 7, 7]       1,024                True
│    │    └─ReLU (relu)                  [8, 512, 7, 7]       [8, 512, 7, 7]       --                   --
│    │    └─Conv2d (conv3)               [8, 512, 7, 7]       [8, 2048, 7, 7]      1,048,576            True
│    │    └─BatchNorm2d (bn3)            [8, 2048, 7, 7]      [8, 2048, 7, 7]      4,096                True
│    │    └─ReLU (relu)                  [8, 2048, 7, 7]      [8, 2048, 7, 7]      --                   --
├─AdaptiveAvgPool2d (avgpool)            [8, 2048, 7, 7]      [8, 2048, 1, 1]      --                   --
├─Sequential (fc)                        [8, 2048]            [8, 8]               --                   True
│    └─Linear (0)                        [8, 2048]            [8, 8]               16,392               True
========================================================================================================================
Total params: 23,524,424
Trainable params: 23,299,080
Non-trainable params: 225,344
Total mult-adds (Units.GIGABYTES): 32.70
========================================================================================================================
Input size (MB): 4.82
Forward/backward pass size (MB): 1422.59
Params size (MB): 94.10
Estimated Total Size (MB): 1521.51
========================================================================================================================
Epoch [1/40] - Train Loss: 1.1077, Train Accuracy: 0.6319, Val Loss: 0.5276, Val Accuracy: 0.8387
Test Loss: 0.4960, Test Accuracy: 0.8538
Epoch [2/40] - Train Loss: 0.6702, Train Accuracy: 0.7750, Val Loss: 0.4173, Val Accuracy: 0.8762
Test Loss: 0.3821, Test Accuracy: 0.8825
Epoch [3/40] - Train Loss: 0.5467, Train Accuracy: 0.8125, Val Loss: 0.4349, Val Accuracy: 0.8800
Test Loss: 0.3952, Test Accuracy: 0.8800
Epoch [4/40] - Train Loss: 0.4843, Train Accuracy: 0.8383, Val Loss: 0.4707, Val Accuracy: 0.8762
Test Loss: 0.4927, Test Accuracy: 0.8900
Epoch [5/40] - Train Loss: 0.4396, Train Accuracy: 0.8509, Val Loss: 0.4072, Val Accuracy: 0.8944
Test Loss: 0.4866, Test Accuracy: 0.8838
Epoch [6/40] - Train Loss: 0.4080, Train Accuracy: 0.8589, Val Loss: 0.3280, Val Accuracy: 0.9000
Test Loss: 0.3115, Test Accuracy: 0.9038
Epoch [7/40] - Train Loss: 0.3840, Train Accuracy: 0.8711, Val Loss: 0.3467, Val Accuracy: 0.9062
Test Loss: 0.2993, Test Accuracy: 0.9187
Epoch [8/40] - Train Loss: 0.3527, Train Accuracy: 0.8731, Val Loss: 0.3543, Val Accuracy: 0.9081
Test Loss: 0.3055, Test Accuracy: 0.9125
Epoch [9/40] - Train Loss: 0.3209, Train Accuracy: 0.8864, Val Loss: 0.3260, Val Accuracy: 0.9144
Test Loss: 0.3049, Test Accuracy: 0.9213
Epoch [10/40] - Train Loss: 0.3031, Train Accuracy: 0.8948, Val Loss: 0.5509, Val Accuracy: 0.9062
Test Loss: 0.4246, Test Accuracy: 0.9087
Epoch [11/40] - Train Loss: 0.2862, Train Accuracy: 0.8986, Val Loss: 0.4436, Val Accuracy: 0.9156
Test Loss: 0.3557, Test Accuracy: 0.9150
Epoch [12/40] - Train Loss: 0.2604, Train Accuracy: 0.9098, Val Loss: 1.2798, Val Accuracy: 0.9031
Test Loss: 0.6929, Test Accuracy: 0.9038
Epoch [13/40] - Train Loss: 0.2637, Train Accuracy: 0.9059, Val Loss: 0.7528, Val Accuracy: 0.9044
Test Loss: 0.4569, Test Accuracy: 0.9125
Epoch [14/40] - Train Loss: 0.2517, Train Accuracy: 0.9137, Val Loss: 0.6799, Val Accuracy: 0.9219
Test Loss: 0.4147, Test Accuracy: 0.9225
Epoch [15/40] - Train Loss: 0.2387, Train Accuracy: 0.9189, Val Loss: 0.5641, Val Accuracy: 0.9175
Test Loss: 0.3643, Test Accuracy: 0.9175
Epoch [16/40] - Train Loss: 0.2180, Train Accuracy: 0.9297, Val Loss: 0.3824, Val Accuracy: 0.9213
Test Loss: 0.3298, Test Accuracy: 0.9175
Epoch [17/40] - Train Loss: 0.2033, Train Accuracy: 0.9302, Val Loss: 0.5917, Val Accuracy: 0.9075
Test Loss: 0.3985, Test Accuracy: 0.9150
Epoch [18/40] - Train Loss: 0.2277, Train Accuracy: 0.9219, Val Loss: 0.3795, Val Accuracy: 0.9237
Test Loss: 0.4759, Test Accuracy: 0.9225
Epoch [19/40] - Train Loss: 0.2172, Train Accuracy: 0.9253, Val Loss: 0.3420, Val Accuracy: 0.9300
Test Loss: 0.3484, Test Accuracy: 0.9263
Epoch [20/40] - Train Loss: 0.1904, Train Accuracy: 0.9350, Val Loss: 0.4314, Val Accuracy: 0.9225
Test Loss: 0.3176, Test Accuracy: 0.9163
Epoch [21/40] - Train Loss: 0.2035, Train Accuracy: 0.9300, Val Loss: 0.5804, Val Accuracy: 0.9244
Test Loss: 0.5229, Test Accuracy: 0.9025
Epoch [22/40] - Train Loss: 0.1902, Train Accuracy: 0.9348, Val Loss: 0.7004, Val Accuracy: 0.9244
Test Loss: 0.4777, Test Accuracy: 0.9050
Epoch [23/40] - Train Loss: 0.1730, Train Accuracy: 0.9406, Val Loss: 0.6073, Val Accuracy: 0.9150
Test Loss: 0.4145, Test Accuracy: 0.9062
Epoch [24/40] - Train Loss: 0.1860, Train Accuracy: 0.9348, Val Loss: 0.3329, Val Accuracy: 0.9250
Test Loss: 0.3784, Test Accuracy: 0.9062
Epoch [25/40] - Train Loss: 0.1838, Train Accuracy: 0.9386, Val Loss: 0.6658, Val Accuracy: 0.9237
Test Loss: 0.6443, Test Accuracy: 0.9263
Epoch [26/40] - Train Loss: 0.1670, Train Accuracy: 0.9416, Val Loss: 0.6619, Val Accuracy: 0.9250
Test Loss: 0.6266, Test Accuracy: 0.9150
Epoch [27/40] - Train Loss: 0.1774, Train Accuracy: 0.9417, Val Loss: 0.4042, Val Accuracy: 0.9275
Test Loss: 0.3599, Test Accuracy: 0.9200
Epoch [28/40] - Train Loss: 0.1681, Train Accuracy: 0.9408, Val Loss: 0.6540, Val Accuracy: 0.9144
Test Loss: 0.5764, Test Accuracy: 0.9150
Epoch [29/40] - Train Loss: 0.1475, Train Accuracy: 0.9487, Val Loss: 0.9916, Val Accuracy: 0.9181
Test Loss: 0.9103, Test Accuracy: 0.9012
Epoch [30/40] - Train Loss: 0.1558, Train Accuracy: 0.9492, Val Loss: 0.7179, Val Accuracy: 0.9163
Test Loss: 0.6632, Test Accuracy: 0.9137
Epoch [31/40] - Train Loss: 0.1459, Train Accuracy: 0.9545, Val Loss: 0.4600, Val Accuracy: 0.9250
Test Loss: 0.4331, Test Accuracy: 0.9125
Epoch [32/40] - Train Loss: 0.1482, Train Accuracy: 0.9520, Val Loss: 0.3439, Val Accuracy: 0.9350
Test Loss: 0.3974, Test Accuracy: 0.9263
Epoch [33/40] - Train Loss: 0.1421, Train Accuracy: 0.9547, Val Loss: 0.6173, Val Accuracy: 0.9187
Test Loss: 0.5931, Test Accuracy: 0.9113
Epoch [34/40] - Train Loss: 0.1423, Train Accuracy: 0.9513, Val Loss: 0.3962, Val Accuracy: 0.9194
Test Loss: 0.3579, Test Accuracy: 0.9200
Epoch [35/40] - Train Loss: 0.1449, Train Accuracy: 0.9509, Val Loss: 0.5834, Val Accuracy: 0.9206
Test Loss: 0.4744, Test Accuracy: 0.9025
Epoch [36/40] - Train Loss: 0.1424, Train Accuracy: 0.9498, Val Loss: 0.6933, Val Accuracy: 0.9237
Test Loss: 0.5532, Test Accuracy: 0.9100
Epoch [37/40] - Train Loss: 0.1366, Train Accuracy: 0.9550, Val Loss: 0.3432, Val Accuracy: 0.9269
Test Loss: 0.3094, Test Accuracy: 0.9200
Epoch [38/40] - Train Loss: 0.1441, Train Accuracy: 0.9494, Val Loss: 0.6550, Val Accuracy: 0.9225
Test Loss: 0.6152, Test Accuracy: 0.9125
Epoch [39/40] - Train Loss: 0.1287, Train Accuracy: 0.9563, Val Loss: 0.3611, Val Accuracy: 0.9231
Test Loss: 0.3379, Test Accuracy: 0.9225
Epoch [40/40] - Train Loss: 0.1368, Train Accuracy: 0.9552, Val Loss: 0.3624, Val Accuracy: 0.9306
Test Loss: 0.3330, Test Accuracy: 0.9263
Start time: 2023-08-11 08:54:43.941604
End time: 2023-08-11 09:09:01.833905
Total time: 0:14:17.892301
