{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CS4921 Lab 2 - Alexander Huang\n",
      "Library Versions:\n",
      "numpy: 1.22.4\n",
      "pandas: 1.5.2\n",
      "tensorflow: 2.6.0\n",
      "tensorflow probability: 0.14.0\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(\"CS4921 Lab 2 - Alexander Huang\")\n",
    "print(\"Library Versions:\")\n",
    "print('numpy:',np.__version__)\n",
    "print('pandas:',pd.__version__)\n",
    "print('tensorflow:',tf.__version__)\n",
    "print('tensorflow probability:', tfp.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of epochs\n",
    "n_linear_epochs = 300\n",
    "n_nn_epochs = 300\n",
    "n_ion_epochs = 300\n",
    "verbose_option = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# California Housing Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20640 entries, 0 to 20639\n",
      "Data columns (total 9 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   longitude         20640 non-null  float64\n",
      " 1   latitude          20640 non-null  float64\n",
      " 2   housingMedianAge  20640 non-null  int64  \n",
      " 3   totalRooms        20640 non-null  int64  \n",
      " 4   totalBedrooms     20640 non-null  int64  \n",
      " 5   population        20640 non-null  int64  \n",
      " 6   households        20640 non-null  int64  \n",
      " 7   medianIncome      20640 non-null  float64\n",
      " 8   medianHouseValue  20640 non-null  int64  \n",
      "dtypes: float64(3), int64(6)\n",
      "memory usage: 1.4 MB\n",
      "Null values\n",
      "longitude           0\n",
      "latitude            0\n",
      "housingMedianAge    0\n",
      "totalRooms          0\n",
      "totalBedrooms       0\n",
      "population          0\n",
      "households          0\n",
      "medianIncome        0\n",
      "medianHouseValue    0\n",
      "dtype: int64\n",
      "   longitude  latitude  housingMedianAge  totalRooms  totalBedrooms  \\\n",
      "0    -122.23     37.88                41         880            129   \n",
      "1    -122.22     37.86                21        7099           1106   \n",
      "2    -122.24     37.85                52        1467            190   \n",
      "3    -122.25     37.85                52        1274            235   \n",
      "4    -122.25     37.85                52        1627            280   \n",
      "\n",
      "   population  households  medianIncome  medianHouseValue  \n",
      "0         322         126        8.3252            452600  \n",
      "1        2401        1138        8.3014            358500  \n",
      "2         496         177        7.2574            352100  \n",
      "3         558         219        5.6431            341300  \n",
      "4         565         259        3.8462            342200  \n",
      "          longitude      latitude  housingMedianAge    totalRooms  \\\n",
      "count  20640.000000  20640.000000      20640.000000  20640.000000   \n",
      "mean    -119.569704     35.631861         28.639486   2635.763081   \n",
      "std        2.003532      2.135952         12.585558   2181.615252   \n",
      "min     -124.350000     32.540000          1.000000      2.000000   \n",
      "25%     -121.800000     33.930000         18.000000   1447.750000   \n",
      "50%     -118.490000     34.260000         29.000000   2127.000000   \n",
      "75%     -118.010000     37.710000         37.000000   3148.000000   \n",
      "max     -114.310000     41.950000         52.000000  39320.000000   \n",
      "\n",
      "       totalBedrooms    population    households  medianIncome  \\\n",
      "count   20640.000000  20640.000000  20640.000000  20640.000000   \n",
      "mean      537.898014   1425.476744    499.539680      3.870671   \n",
      "std       421.247906   1132.462122    382.329753      1.899822   \n",
      "min         1.000000      3.000000      1.000000      0.499900   \n",
      "25%       295.000000    787.000000    280.000000      2.563400   \n",
      "50%       435.000000   1166.000000    409.000000      3.534800   \n",
      "75%       647.000000   1725.000000    605.000000      4.743250   \n",
      "max      6445.000000  35682.000000   6082.000000     15.000100   \n",
      "\n",
      "       medianHouseValue  \n",
      "count      20640.000000  \n",
      "mean      206855.816909  \n",
      "std       115395.615874  \n",
      "min        14999.000000  \n",
      "25%       119600.000000  \n",
      "50%       179700.000000  \n",
      "75%       264725.000000  \n",
      "max       500001.000000  \n",
      "Features\n",
      "       longitude  latitude  housingMedianAge  totalRooms  totalBedrooms  \\\n",
      "0        -122.23     37.88                41         880            129   \n",
      "1        -122.22     37.86                21        7099           1106   \n",
      "2        -122.24     37.85                52        1467            190   \n",
      "3        -122.25     37.85                52        1274            235   \n",
      "4        -122.25     37.85                52        1627            280   \n",
      "...          ...       ...               ...         ...            ...   \n",
      "20635    -121.09     39.48                25        1665            374   \n",
      "20636    -121.21     39.49                18         697            150   \n",
      "20637    -121.22     39.43                17        2254            485   \n",
      "20638    -121.32     39.43                18        1860            409   \n",
      "20639    -121.24     39.37                16        2785            616   \n",
      "\n",
      "       population  households  medianIncome  \n",
      "0             322         126        8.3252  \n",
      "1            2401        1138        8.3014  \n",
      "2             496         177        7.2574  \n",
      "3             558         219        5.6431  \n",
      "4             565         259        3.8462  \n",
      "...           ...         ...           ...  \n",
      "20635         845         330        1.5603  \n",
      "20636         356         114        2.5568  \n",
      "20637        1007         433        1.7000  \n",
      "20638         741         349        1.8672  \n",
      "20639        1387         530        2.3886  \n",
      "\n",
      "[20640 rows x 8 columns]\n",
      "Target\n",
      "       medianHouseValue\n",
      "0                452600\n",
      "1                358500\n",
      "2                352100\n",
      "3                341300\n",
      "4                342200\n",
      "...                 ...\n",
      "20635             78100\n",
      "20636             77100\n",
      "20637             92300\n",
      "20638             84700\n",
      "20639             89400\n",
      "\n",
      "[20640 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "# Import Dataset\n",
    "cali_data = pd.read_csv('cal_housing.csv')\n",
    "air_data = pd.read_table('airfoil_self_noise.dat', header=None)\n",
    "\n",
    "# Data Exploration\n",
    "labels = {'longitude: continuous.': 'longitude',\n",
    "          'latitude: continuous.': 'latitude',\n",
    "          'housingMedianAge: continuous. ': 'housingMedianAge',\n",
    "          'totalRooms: continuous. ': 'totalRooms',\n",
    "          'totalBedrooms: continuous. ': 'totalBedrooms',\n",
    "          'population: continuous. ': 'population',\n",
    "          'households: continuous. ': 'households',\n",
    "          'medianIncome: continuous. ': 'medianIncome',\n",
    "          'medianHouseValue: continuous. ': 'medianHouseValue'\n",
    "         }\n",
    "# Change the columns to something reasonable\n",
    "cali_data = cali_data.rename(columns=labels)\n",
    "\n",
    "cali_data.info()\n",
    "print('Null values')\n",
    "print(cali_data.isnull().sum())\n",
    "print(cali_data.head())\n",
    "print(cali_data.describe())\n",
    "\n",
    "# feature engineering 8 -> 7 features\n",
    "#cali_data['numRooms'] = cali_data['totalRooms']/cali_data['households']\n",
    "#cali_data['numBedrooms'] = cali_data['totalBedrooms']/cali_data['households']\n",
    "#cali_data['personsPerHouse'] = cali_data['population']/cali_data['households']\n",
    "#cali_data = cali_data.drop(['totalRooms', 'totalBedrooms', 'population', 'households'], axis=1)\n",
    "\n",
    "#air_data.info()\n",
    "# Split features and labels\n",
    "y = cali_data['medianHouseValue'].to_frame()\n",
    "x = cali_data.drop(['medianHouseValue'], axis=1)\n",
    "\n",
    "#y = air_data.iloc[:,5]\n",
    "#x = air_data.iloc[:,0:5]\n",
    "print('Features')\n",
    "print(x)\n",
    "print('Target')\n",
    "print(y)\n",
    "\n",
    "\n",
    "y_mu=y.to_numpy().mean()\n",
    "y_sigma=y.to_numpy().std()\n",
    "y_orig = y.to_numpy().flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: [[-1.79368219 -1.79229467 -1.79226763 ... -1.78983247 -1.79153102\n",
      "  -1.79255079]\n",
      " [-1.7936821  -1.79229484 -1.79244095 ... -1.77181575 -1.78276097\n",
      "  -1.792551  ]\n",
      " [-1.79368228 -1.79229493 -1.7921723  ... -1.78832458 -1.79108905\n",
      "  -1.79256005]\n",
      " ...\n",
      " [-1.79367344 -1.79228124 -1.79247562 ... -1.78389623 -1.78887054\n",
      "  -1.79260821]\n",
      " [-1.7936743  -1.79228124 -1.79246695 ... -1.7862014  -1.78959849\n",
      "  -1.79260676]\n",
      " [-1.79367361 -1.79228176 -1.79248428 ... -1.78060313 -1.78802993\n",
      "  -1.79260224]]\n",
      "(20640, 8)\n",
      "y: [[ 2.12963148]\n",
      " [ 1.31415614]\n",
      " [ 1.25869341]\n",
      " ...\n",
      " [-0.99274649]\n",
      " [-1.05860847]\n",
      " [-1.01787803]]\n",
      "(20640, 1)\n"
     ]
    }
   ],
   "source": [
    "# Scaling\n",
    "scale = lambda y: (y-y_mu)/y_sigma\n",
    "unscale = lambda y: y_sigma*y+y_mu\n",
    "\n",
    "x = scale(x.to_numpy())\n",
    "y = scale(y.to_numpy())\n",
    "print('x:', x)\n",
    "print(x.shape)\n",
    "print('y:', y)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_examples = y.shape[0]\n",
    "expectNLL = lambda y, rv_y: -rv_y.log_prob(y)/n_examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span>1.</span>Using Pytorch or Tensoflow, perform Maximum Likelihood Estimation (MLE) for a linear Gaussian\n",
    "prediction model with homoscedastic uncertainty for the California housing price dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"HousingLinearModel\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_19 (InputLayer)        [(None, 8)]               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 9         \n",
      "_________________________________________________________________\n",
      "distribution_lambda_1 (Distr multiple                  0         \n",
      "=================================================================\n",
      "Total params: 9\n",
      "Trainable params: 9\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "input = tf.keras.layers.Input(8)\n",
    "linear = tf.keras.layers.Dense(1)(input)\n",
    "s = tfp.layers.VariableLayer(shape=[1], activation=tf.keras.activations.exponential)(True)\n",
    "p = tfp.layers.DistributionLambda(lambda t: tfp.distributions.Normal(loc=t[0], scale=t[1]))([linear,s])\n",
    "model = tf.keras.Model(inputs=input, outputs=p, name=\"HousingLinearModel\")\n",
    "\n",
    "model.compile(optimizer=tf.optimizers.Adam(learning_rate=0.01), loss=expectNLL)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-27 05:47:35.085563: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "645/645 [==============================] - 1s 1ms/step - loss: 7.1127e-05\n",
      "Epoch 2/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8895e-05\n",
      "Epoch 3/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8949e-05\n",
      "Epoch 4/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8967e-05\n",
      "Epoch 5/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8898e-05\n",
      "Epoch 6/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8937e-05\n",
      "Epoch 7/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.9006e-05\n",
      "Epoch 8/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8943e-05\n",
      "Epoch 9/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8976e-05\n",
      "Epoch 10/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8859e-05\n",
      "Epoch 11/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.9040e-05\n",
      "Epoch 12/300\n",
      "645/645 [==============================] - 1s 865us/step - loss: 6.8927e-05\n",
      "Epoch 13/300\n",
      "645/645 [==============================] - 1s 926us/step - loss: 6.8961e-05\n",
      "Epoch 14/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8896e-05\n",
      "Epoch 15/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8877e-05\n",
      "Epoch 16/300\n",
      "645/645 [==============================] - 1s 850us/step - loss: 6.9067e-05\n",
      "Epoch 17/300\n",
      "645/645 [==============================] - 1s 805us/step - loss: 6.8840e-05\n",
      "Epoch 18/300\n",
      "645/645 [==============================] - 1s 841us/step - loss: 6.9033e-05\n",
      "Epoch 19/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8915e-05\n",
      "Epoch 20/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8892e-05\n",
      "Epoch 21/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8916e-05\n",
      "Epoch 22/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.9002e-05\n",
      "Epoch 23/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8909e-05\n",
      "Epoch 24/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8870e-05\n",
      "Epoch 25/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8950e-05\n",
      "Epoch 26/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8865e-05\n",
      "Epoch 27/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8842e-05\n",
      "Epoch 28/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8936e-05\n",
      "Epoch 29/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8833e-05\n",
      "Epoch 30/300\n",
      "645/645 [==============================] - 1s 967us/step - loss: 6.8986e-05\n",
      "Epoch 31/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8923e-05\n",
      "Epoch 32/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8922e-05\n",
      "Epoch 33/300\n",
      "645/645 [==============================] - 1s 803us/step - loss: 6.8808e-05\n",
      "Epoch 34/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8900e-05\n",
      "Epoch 35/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8822e-05\n",
      "Epoch 36/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8771e-05\n",
      "Epoch 37/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8826e-05\n",
      "Epoch 38/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8793e-05\n",
      "Epoch 39/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8825e-05\n",
      "Epoch 40/300\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 6.8813e-05\n",
      "Epoch 41/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8796e-05\n",
      "Epoch 42/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8793e-05\n",
      "Epoch 43/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8858e-05\n",
      "Epoch 44/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8835e-05\n",
      "Epoch 45/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8812e-05\n",
      "Epoch 46/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8866e-05\n",
      "Epoch 47/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8790e-05\n",
      "Epoch 48/300\n",
      "645/645 [==============================] - 1s 888us/step - loss: 6.8818e-05\n",
      "Epoch 49/300\n",
      "645/645 [==============================] - 1s 887us/step - loss: 6.8870e-05\n",
      "Epoch 50/300\n",
      "645/645 [==============================] - 1s 925us/step - loss: 6.8909e-05\n",
      "Epoch 51/300\n",
      "645/645 [==============================] - 1s 887us/step - loss: 6.8727e-05\n",
      "Epoch 52/300\n",
      "645/645 [==============================] - 1s 858us/step - loss: 6.8757e-05\n",
      "Epoch 53/300\n",
      "645/645 [==============================] - 1s 877us/step - loss: 6.8832e-05\n",
      "Epoch 54/300\n",
      "645/645 [==============================] - 1s 970us/step - loss: 6.8789e-05\n",
      "Epoch 55/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8792e-05\n",
      "Epoch 56/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8752e-05\n",
      "Epoch 57/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8791e-05\n",
      "Epoch 58/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8832e-05\n",
      "Epoch 59/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8771e-05\n",
      "Epoch 60/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8850e-05\n",
      "Epoch 61/300\n",
      "645/645 [==============================] - 1s 865us/step - loss: 6.8722e-05\n",
      "Epoch 62/300\n",
      "645/645 [==============================] - 1s 888us/step - loss: 6.8792e-05\n",
      "Epoch 63/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8737e-05\n",
      "Epoch 64/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8726e-05\n",
      "Epoch 65/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8705e-05\n",
      "Epoch 66/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8785e-05\n",
      "Epoch 67/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8748e-05\n",
      "Epoch 68/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8751e-05\n",
      "Epoch 69/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8764e-05\n",
      "Epoch 70/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8655e-05\n",
      "Epoch 71/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8714e-05\n",
      "Epoch 72/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8731e-05\n",
      "Epoch 73/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8846e-05\n",
      "Epoch 74/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8744e-05\n",
      "Epoch 75/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8714e-05\n",
      "Epoch 76/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8648e-05\n",
      "Epoch 77/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8742e-05\n",
      "Epoch 78/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8668e-05\n",
      "Epoch 79/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8697e-05\n",
      "Epoch 80/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8736e-05\n",
      "Epoch 81/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8758e-05\n",
      "Epoch 82/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8668e-05\n",
      "Epoch 83/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8674e-05\n",
      "Epoch 84/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8675e-05\n",
      "Epoch 85/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8681e-05\n",
      "Epoch 86/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8591e-05\n",
      "Epoch 87/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8691e-05\n",
      "Epoch 88/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8675e-05\n",
      "Epoch 89/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8739e-05\n",
      "Epoch 90/300\n",
      "645/645 [==============================] - 1s 976us/step - loss: 6.8633e-05\n",
      "Epoch 91/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8843e-05\n",
      "Epoch 92/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8628e-05\n",
      "Epoch 93/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8571e-05\n",
      "Epoch 94/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8659e-05\n",
      "Epoch 95/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8662e-05\n",
      "Epoch 96/300\n",
      "645/645 [==============================] - 1s 937us/step - loss: 6.8615e-05\n",
      "Epoch 97/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8635e-05\n",
      "Epoch 98/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8703e-05\n",
      "Epoch 99/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8706e-05\n",
      "Epoch 100/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8698e-05\n",
      "Epoch 101/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8652e-05\n",
      "Epoch 102/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8688e-05\n",
      "Epoch 103/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8640e-05\n",
      "Epoch 104/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8717e-05\n",
      "Epoch 105/300\n",
      "645/645 [==============================] - 1s 936us/step - loss: 6.8643e-05\n",
      "Epoch 106/300\n",
      "645/645 [==============================] - 1s 848us/step - loss: 6.8683e-05\n",
      "Epoch 107/300\n",
      "645/645 [==============================] - 1s 885us/step - loss: 6.8697e-05\n",
      "Epoch 108/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8783e-05\n",
      "Epoch 109/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8595e-05\n",
      "Epoch 110/300\n",
      "645/645 [==============================] - 1s 927us/step - loss: 6.8685e-05\n",
      "Epoch 111/300\n",
      "645/645 [==============================] - 1s 932us/step - loss: 6.8652e-05\n",
      "Epoch 112/300\n",
      "645/645 [==============================] - 0s 760us/step - loss: 6.8628e-05\n",
      "Epoch 113/300\n",
      "645/645 [==============================] - 1s 778us/step - loss: 6.8653e-05\n",
      "Epoch 114/300\n",
      "645/645 [==============================] - 1s 977us/step - loss: 6.8738e-05\n",
      "Epoch 115/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8597e-05\n",
      "Epoch 116/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8575e-05\n",
      "Epoch 117/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8560e-05\n",
      "Epoch 118/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8642e-05\n",
      "Epoch 119/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8564e-05\n",
      "Epoch 120/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8683e-05\n",
      "Epoch 121/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8675e-05\n",
      "Epoch 122/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8647e-05\n",
      "Epoch 123/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8688e-05\n",
      "Epoch 124/300\n",
      "645/645 [==============================] - 1s 992us/step - loss: 6.8564e-05\n",
      "Epoch 125/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8549e-05\n",
      "Epoch 126/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8577e-05\n",
      "Epoch 127/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8572e-05\n",
      "Epoch 128/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8572e-05\n",
      "Epoch 129/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8564e-05\n",
      "Epoch 130/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8661e-05\n",
      "Epoch 131/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8593e-05\n",
      "Epoch 132/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8618e-05\n",
      "Epoch 133/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8519e-05\n",
      "Epoch 134/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8566e-05\n",
      "Epoch 135/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8606e-05\n",
      "Epoch 136/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8587e-05\n",
      "Epoch 137/300\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 6.8573e-05\n",
      "Epoch 138/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8609e-05\n",
      "Epoch 139/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8507e-05\n",
      "Epoch 140/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8557e-05\n",
      "Epoch 141/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8542e-05\n",
      "Epoch 142/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8763e-05\n",
      "Epoch 143/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8601e-05\n",
      "Epoch 144/300\n",
      "645/645 [==============================] - 1s 818us/step - loss: 6.8611e-05\n",
      "Epoch 145/300\n",
      "645/645 [==============================] - 0s 734us/step - loss: 6.8618e-05\n",
      "Epoch 146/300\n",
      "645/645 [==============================] - 0s 729us/step - loss: 6.8461e-05\n",
      "Epoch 147/300\n",
      "645/645 [==============================] - 0s 707us/step - loss: 6.8571e-05\n",
      "Epoch 148/300\n",
      "645/645 [==============================] - 0s 726us/step - loss: 6.8489e-05\n",
      "Epoch 149/300\n",
      "645/645 [==============================] - 1s 783us/step - loss: 6.8492e-05\n",
      "Epoch 150/300\n",
      "645/645 [==============================] - 1s 880us/step - loss: 6.8495e-05\n",
      "Epoch 151/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8669e-05\n",
      "Epoch 152/300\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 6.8631e-05\n",
      "Epoch 153/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8671e-05\n",
      "Epoch 154/300\n",
      "645/645 [==============================] - 1s 975us/step - loss: 6.8510e-05\n",
      "Epoch 155/300\n",
      "645/645 [==============================] - 1s 913us/step - loss: 6.8532e-05\n",
      "Epoch 156/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8569e-05\n",
      "Epoch 157/300\n",
      "645/645 [==============================] - 1s 825us/step - loss: 6.8574e-05\n",
      "Epoch 158/300\n",
      "645/645 [==============================] - 1s 930us/step - loss: 6.8552e-05\n",
      "Epoch 159/300\n",
      "645/645 [==============================] - 1s 819us/step - loss: 6.8558e-05\n",
      "Epoch 160/300\n",
      "645/645 [==============================] - 1s 886us/step - loss: 6.8593e-05\n",
      "Epoch 161/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8605e-05\n",
      "Epoch 162/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8553e-05\n",
      "Epoch 163/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8563e-05\n",
      "Epoch 164/300\n",
      "645/645 [==============================] - 1s 918us/step - loss: 6.8536e-05\n",
      "Epoch 165/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8524e-05\n",
      "Epoch 166/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8525e-05\n",
      "Epoch 167/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8571e-05\n",
      "Epoch 168/300\n",
      "645/645 [==============================] - 1s 865us/step - loss: 6.8522e-05\n",
      "Epoch 169/300\n",
      "645/645 [==============================] - 1s 871us/step - loss: 6.8549e-05\n",
      "Epoch 170/300\n",
      "645/645 [==============================] - 1s 857us/step - loss: 6.8532e-05\n",
      "Epoch 171/300\n",
      "645/645 [==============================] - 1s 863us/step - loss: 6.8501e-05\n",
      "Epoch 172/300\n",
      "645/645 [==============================] - 1s 875us/step - loss: 6.8613e-05\n",
      "Epoch 173/300\n",
      "645/645 [==============================] - 1s 897us/step - loss: 6.8498e-05\n",
      "Epoch 174/300\n",
      "645/645 [==============================] - 1s 817us/step - loss: 6.8467e-05\n",
      "Epoch 175/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8500e-05\n",
      "Epoch 176/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8517e-05\n",
      "Epoch 177/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8485e-05\n",
      "Epoch 178/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8546e-05\n",
      "Epoch 179/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8475e-05\n",
      "Epoch 180/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8536e-05\n",
      "Epoch 181/300\n",
      "645/645 [==============================] - 1s 899us/step - loss: 6.8506e-05\n",
      "Epoch 182/300\n",
      "645/645 [==============================] - 1s 812us/step - loss: 6.8463e-05\n",
      "Epoch 183/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8520e-05\n",
      "Epoch 184/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8501e-05\n",
      "Epoch 185/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8488e-05\n",
      "Epoch 186/300\n",
      "645/645 [==============================] - 1s 994us/step - loss: 6.8476e-05\n",
      "Epoch 187/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8480e-05\n",
      "Epoch 188/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8455e-05\n",
      "Epoch 189/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8524e-05\n",
      "Epoch 190/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8469e-05\n",
      "Epoch 191/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8511e-05\n",
      "Epoch 192/300\n",
      "645/645 [==============================] - 1s 964us/step - loss: 6.8454e-05\n",
      "Epoch 193/300\n",
      "645/645 [==============================] - 1s 837us/step - loss: 6.8481e-05\n",
      "Epoch 194/300\n",
      "645/645 [==============================] - 1s 835us/step - loss: 6.8472e-05\n",
      "Epoch 195/300\n",
      "645/645 [==============================] - 1s 799us/step - loss: 6.8475e-05\n",
      "Epoch 196/300\n",
      "645/645 [==============================] - 1s 907us/step - loss: 6.8515e-05\n",
      "Epoch 197/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8454e-05\n",
      "Epoch 198/300\n",
      "645/645 [==============================] - 1s 838us/step - loss: 6.8556e-05\n",
      "Epoch 199/300\n",
      "645/645 [==============================] - 1s 795us/step - loss: 6.8504e-05\n",
      "Epoch 200/300\n",
      "645/645 [==============================] - 0s 750us/step - loss: 6.8464e-05\n",
      "Epoch 201/300\n",
      "645/645 [==============================] - 1s 992us/step - loss: 6.8386e-05\n",
      "Epoch 202/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8489e-05\n",
      "Epoch 203/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8432e-05\n",
      "Epoch 204/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8491e-05\n",
      "Epoch 205/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8393e-05\n",
      "Epoch 206/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8471e-05\n",
      "Epoch 207/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8528e-05\n",
      "Epoch 208/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8440e-05\n",
      "Epoch 209/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8387e-05\n",
      "Epoch 210/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8472e-05\n",
      "Epoch 211/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8497e-05\n",
      "Epoch 212/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8449e-05\n",
      "Epoch 213/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8346e-05\n",
      "Epoch 214/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8471e-05\n",
      "Epoch 215/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8439e-05\n",
      "Epoch 216/300\n",
      "645/645 [==============================] - 1s 936us/step - loss: 6.8526e-05\n",
      "Epoch 217/300\n",
      "645/645 [==============================] - 1s 914us/step - loss: 6.8380e-05\n",
      "Epoch 218/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8471e-05\n",
      "Epoch 219/300\n",
      "645/645 [==============================] - 1s 885us/step - loss: 6.8444e-05\n",
      "Epoch 220/300\n",
      "645/645 [==============================] - 1s 926us/step - loss: 6.8473e-05\n",
      "Epoch 221/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8463e-05\n",
      "Epoch 222/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8384e-05\n",
      "Epoch 223/300\n",
      "645/645 [==============================] - 1s 933us/step - loss: 6.8403e-05\n",
      "Epoch 224/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8433e-05\n",
      "Epoch 225/300\n",
      "645/645 [==============================] - 1s 855us/step - loss: 6.8513e-05\n",
      "Epoch 226/300\n",
      "645/645 [==============================] - 0s 713us/step - loss: 6.8528e-05\n",
      "Epoch 227/300\n",
      "645/645 [==============================] - 0s 715us/step - loss: 6.8544e-05\n",
      "Epoch 228/300\n",
      "645/645 [==============================] - 1s 845us/step - loss: 6.8411e-05\n",
      "Epoch 229/300\n",
      "645/645 [==============================] - 0s 745us/step - loss: 6.8499e-05\n",
      "Epoch 230/300\n",
      "645/645 [==============================] - 0s 772us/step - loss: 6.8418e-05\n",
      "Epoch 231/300\n",
      "645/645 [==============================] - 1s 792us/step - loss: 6.8458e-05\n",
      "Epoch 232/300\n",
      "645/645 [==============================] - 1s 799us/step - loss: 6.8456e-05\n",
      "Epoch 233/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8446e-05\n",
      "Epoch 234/300\n",
      "645/645 [==============================] - 1s 907us/step - loss: 6.8459e-05\n",
      "Epoch 235/300\n",
      "645/645 [==============================] - 1s 804us/step - loss: 6.8363e-05\n",
      "Epoch 236/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8425e-05\n",
      "Epoch 237/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8460e-05\n",
      "Epoch 238/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8536e-05\n",
      "Epoch 239/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8301e-05\n",
      "Epoch 240/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8417e-05\n",
      "Epoch 241/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8467e-05\n",
      "Epoch 242/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8497e-05\n",
      "Epoch 243/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8384e-05\n",
      "Epoch 244/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8501e-05\n",
      "Epoch 245/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8447e-05\n",
      "Epoch 246/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8446e-05\n",
      "Epoch 247/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8416e-05\n",
      "Epoch 248/300\n",
      "645/645 [==============================] - 1s 986us/step - loss: 6.8403e-05\n",
      "Epoch 249/300\n",
      "645/645 [==============================] - 1s 815us/step - loss: 6.8404e-05\n",
      "Epoch 250/300\n",
      "645/645 [==============================] - 1s 827us/step - loss: 6.8318e-05\n",
      "Epoch 251/300\n",
      "645/645 [==============================] - 1s 845us/step - loss: 6.8404e-05\n",
      "Epoch 252/300\n",
      "645/645 [==============================] - 1s 832us/step - loss: 6.8368e-05\n",
      "Epoch 253/300\n",
      "645/645 [==============================] - 1s 829us/step - loss: 6.8367e-05\n",
      "Epoch 254/300\n",
      "645/645 [==============================] - 1s 828us/step - loss: 6.8423e-05\n",
      "Epoch 255/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8349e-05\n",
      "Epoch 256/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8373e-05\n",
      "Epoch 257/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8422e-05\n",
      "Epoch 258/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8431e-05\n",
      "Epoch 259/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8518e-05\n",
      "Epoch 260/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8440e-05\n",
      "Epoch 261/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8391e-05\n",
      "Epoch 262/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8363e-05\n",
      "Epoch 263/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8414e-05\n",
      "Epoch 264/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8363e-05\n",
      "Epoch 265/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8462e-05\n",
      "Epoch 266/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8317e-05\n",
      "Epoch 267/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8422e-05\n",
      "Epoch 268/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8387e-05\n",
      "Epoch 269/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8338e-05\n",
      "Epoch 270/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8373e-05\n",
      "Epoch 271/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8352e-05\n",
      "Epoch 272/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8387e-05\n",
      "Epoch 273/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8422e-05\n",
      "Epoch 274/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8346e-05\n",
      "Epoch 275/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8395e-05\n",
      "Epoch 276/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8337e-05\n",
      "Epoch 277/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8342e-05\n",
      "Epoch 278/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8425e-05\n",
      "Epoch 279/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8337e-05\n",
      "Epoch 280/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8315e-05\n",
      "Epoch 281/300\n",
      "645/645 [==============================] - 1s 961us/step - loss: 6.8408e-05\n",
      "Epoch 282/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8376e-05\n",
      "Epoch 283/300\n",
      "645/645 [==============================] - 1s 950us/step - loss: 6.8387e-05\n",
      "Epoch 284/300\n",
      "645/645 [==============================] - 1s 955us/step - loss: 6.8376e-05\n",
      "Epoch 285/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8362e-05\n",
      "Epoch 286/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8342e-05\n",
      "Epoch 287/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8345e-05\n",
      "Epoch 288/300\n",
      "645/645 [==============================] - 1s 2ms/step - loss: 6.8414e-05\n",
      "Epoch 289/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8356e-05\n",
      "Epoch 290/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8288e-05\n",
      "Epoch 291/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8497e-05\n",
      "Epoch 292/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8335e-05\n",
      "Epoch 293/300\n",
      "645/645 [==============================] - 1s 831us/step - loss: 6.8348e-05\n",
      "Epoch 294/300\n",
      "645/645 [==============================] - 1s 825us/step - loss: 6.8449e-05\n",
      "Epoch 295/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8320e-05\n",
      "Epoch 296/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8384e-05\n",
      "Epoch 297/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8318e-05\n",
      "Epoch 298/300\n",
      "645/645 [==============================] - 1s 895us/step - loss: 6.8334e-05\n",
      "Epoch 299/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8354e-05\n",
      "Epoch 300/300\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8294e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa768070f10>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training\n",
    "model.fit(x, y, epochs=n_linear_epochs, verbose=verbose_option)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model mean: tf.Tensor(\n",
      "[[-0.22122586]\n",
      " [ 0.07803237]\n",
      " [-0.1918155 ]\n",
      " ...\n",
      " [-0.16441166]\n",
      " [-0.17819703]\n",
      " [-0.14659417]], shape=(20640, 1), dtype=float32)\n",
      "Model standard deviation: tf.Tensor(\n",
      "[[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " ...\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]], shape=(20640, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "y_dist = model(x)\n",
    "print('Model mean:', y_dist.mean())\n",
    "print('Model standard deviation:', y_dist.stddev())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: 107172.695\n",
      "True: 452600\n",
      "Predictions: 201404.1\n",
      "True: 358500\n",
      "Predictions: 292299.3\n",
      "True: 352100\n",
      "Predictions: 147564.3\n",
      "True: 341300\n",
      "Predictions: 257415.05\n",
      "True: 342200\n",
      "Predictions: 470251.0\n",
      "True: 269700\n",
      "Predictions: 218970.72\n",
      "True: 299200\n",
      "Predictions: 86816.664\n",
      "True: 241400\n",
      "Predictions: 152812.72\n",
      "True: 226700\n",
      "Predictions: 267716.56\n",
      "True: 261100\n",
      "RMSE: 162999.93789051851\n"
     ]
    }
   ],
   "source": [
    "yhat1 = model.predict(x)\n",
    "y_pred1 = unscale(yhat1)\n",
    "y_pred1 = y_pred1.flatten()\n",
    "for i in range(10):\n",
    "    print('Predictions:', y_pred1[i])\n",
    "    print('True:', y_orig[i])\n",
    "print('RMSE:', np.sqrt(mean_squared_error(y_orig, y_pred1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"HousingNNModel\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 8)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "hidden1 (Dense)                 (None, 50)           450         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "hidden2 (Dense)                 (None, 50)           2550        hidden1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "hidden3 (Dense)                 (None, 20)           1020        hidden2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "mu (Dense)                      (None, 1)            21          hidden3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sigma (VariableLayer)           (1,)                 1           hidden3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "output (DistributionLambda)     multiple             0           mu[0][0]                         \n",
      "                                                                 sigma[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 4,042\n",
      "Trainable params: 4,042\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "input2 = tf.keras.layers.Input(8)\n",
    "h1 = tf.keras.layers.Dense(50, activation=tf.keras.activations.relu, name=\"hidden1\")(input2)\n",
    "h2 = tf.keras.layers.Dense(50, activation=tf.keras.activations.relu, name=\"hidden2\")(h1)\n",
    "h3 = tf.keras.layers.Dense(20, activation=tf.keras.activations.relu, name=\"hidden3\")(h2)\n",
    "m2 = tf.keras.layers.Dense(1, name=\"mu\")(h3)\n",
    "s2 = tfp.layers.VariableLayer(shape=[1], activation=tf.keras.activations.exponential, name=\"sigma\")(h3)\n",
    "p2 = tfp.layers.DistributionLambda(lambda t: tfp.distributions.Normal(loc=t[0], scale=t[1]), name=\"output\")([m2, s2])\n",
    "model2 = tf.keras.Model(inputs=input2, outputs=p2, name=\"HousingNNModel\")\n",
    "\n",
    "model2.compile(optimizer=tf.optimizers.Adam(learning_rate=0.001), loss=expectNLL)\n",
    "print(model2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "645/645 [==============================] - 2s 2ms/step - loss: 6.8946e-05\n",
      "Epoch 2/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8786e-05\n",
      "Epoch 3/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8785e-05\n",
      "Epoch 4/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8783e-05\n",
      "Epoch 5/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8755e-05\n",
      "Epoch 6/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8757e-05\n",
      "Epoch 7/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8757e-05\n",
      "Epoch 8/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8764e-05\n",
      "Epoch 9/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8758e-05\n",
      "Epoch 10/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8758e-05\n",
      "Epoch 11/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8747e-05\n",
      "Epoch 12/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8758e-05\n",
      "Epoch 13/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8752e-05\n",
      "Epoch 14/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8757e-05\n",
      "Epoch 15/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8757e-05\n",
      "Epoch 16/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8756e-05\n",
      "Epoch 17/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8756e-05\n",
      "Epoch 18/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8753e-05\n",
      "Epoch 19/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8755e-05\n",
      "Epoch 20/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8745e-05\n",
      "Epoch 21/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8754e-05\n",
      "Epoch 22/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8754e-05\n",
      "Epoch 23/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8754e-05\n",
      "Epoch 24/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8754e-05\n",
      "Epoch 25/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8749e-05\n",
      "Epoch 26/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8759e-05\n",
      "Epoch 27/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8758e-05\n",
      "Epoch 28/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8754e-05\n",
      "Epoch 29/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8755e-05\n",
      "Epoch 30/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8753e-05\n",
      "Epoch 31/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8755e-05\n",
      "Epoch 32/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8753e-05\n",
      "Epoch 33/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8754e-05\n",
      "Epoch 34/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8756e-05\n",
      "Epoch 35/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8751e-05\n",
      "Epoch 36/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8758e-05\n",
      "Epoch 37/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8743e-05\n",
      "Epoch 38/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8752e-05\n",
      "Epoch 39/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8755e-05\n",
      "Epoch 40/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8754e-05\n",
      "Epoch 41/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8755e-05\n",
      "Epoch 42/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8754e-05\n",
      "Epoch 43/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8753e-05\n",
      "Epoch 44/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8752e-05\n",
      "Epoch 45/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8749e-05\n",
      "Epoch 46/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8757e-05\n",
      "Epoch 47/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8756e-05\n",
      "Epoch 48/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8755e-05\n",
      "Epoch 49/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8753e-05\n",
      "Epoch 50/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8755e-05\n",
      "Epoch 51/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8749e-05\n",
      "Epoch 52/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8753e-05\n",
      "Epoch 53/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8752e-05\n",
      "Epoch 54/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8757e-05\n",
      "Epoch 55/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8753e-05\n",
      "Epoch 56/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8754e-05\n",
      "Epoch 57/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8753e-05\n",
      "Epoch 58/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8754e-05\n",
      "Epoch 59/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8750e-05\n",
      "Epoch 60/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8752e-05\n",
      "Epoch 61/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8754e-05\n",
      "Epoch 62/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8757e-05\n",
      "Epoch 63/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8752e-05\n",
      "Epoch 64/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8754e-05\n",
      "Epoch 65/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8755e-05\n",
      "Epoch 66/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8754e-05\n",
      "Epoch 67/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8758e-05\n",
      "Epoch 68/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8755e-05\n",
      "Epoch 69/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8755e-05\n",
      "Epoch 70/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8754e-05\n",
      "Epoch 71/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8756e-05\n",
      "Epoch 72/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8753e-05\n",
      "Epoch 73/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8751e-05\n",
      "Epoch 74/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8757e-05\n",
      "Epoch 75/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8751e-05\n",
      "Epoch 76/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8754e-05\n",
      "Epoch 77/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8753e-05\n",
      "Epoch 78/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8755e-05\n",
      "Epoch 79/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8756e-05\n",
      "Epoch 80/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8755e-05\n",
      "Epoch 81/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8753e-05\n",
      "Epoch 82/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8755e-05\n",
      "Epoch 83/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8755e-05\n",
      "Epoch 84/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8755e-05\n",
      "Epoch 85/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8757e-05\n",
      "Epoch 86/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8755e-05\n",
      "Epoch 87/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8754e-05\n",
      "Epoch 88/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8758e-05\n",
      "Epoch 89/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8749e-05\n",
      "Epoch 90/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8754e-05\n",
      "Epoch 91/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8757e-05\n",
      "Epoch 92/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8752e-05\n",
      "Epoch 93/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8756e-05\n",
      "Epoch 94/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8754e-05\n",
      "Epoch 95/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8756e-05\n",
      "Epoch 96/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8755e-05\n",
      "Epoch 97/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8758e-05\n",
      "Epoch 98/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8758e-05\n",
      "Epoch 99/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8752e-05\n",
      "Epoch 100/100\n",
      "645/645 [==============================] - 1s 1ms/step - loss: 6.8756e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa75c557910>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training\n",
    "model2.fit(x, y, epochs=100, verbose=verbose_option)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model mean: tf.Tensor(\n",
      "[[0.00164472]\n",
      " [0.00164472]\n",
      " [0.00164472]\n",
      " ...\n",
      " [0.00164472]\n",
      " [0.00164472]\n",
      " [0.00164472]], shape=(20640, 1), dtype=float32)\n",
      "Model standard deviation: tf.Tensor(\n",
      "[[1.0023664]\n",
      " [1.0023664]\n",
      " [1.0023664]\n",
      " ...\n",
      " [1.0023664]\n",
      " [1.0023664]\n",
      " [1.0023664]], shape=(20640, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "y_dist2 = model2(x)\n",
    "print('Model mean:', y_dist2.mean())\n",
    "print('Model standard deviation:', y_dist2.stddev())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction 0 : 196625.5\n",
      "True 0 : 452600\n",
      "Prediction 1 : 121910.95\n",
      "True 1 : 358500\n",
      "Prediction 2 : 410406.5\n",
      "True 2 : 352100\n",
      "Prediction 3 : 247495.16\n",
      "True 3 : 341300\n",
      "Prediction 4 : 169650.44\n",
      "True 4 : 342200\n",
      "Prediction 5 : 184892.45\n",
      "True 5 : 269700\n",
      "Prediction 6 : 153600.25\n",
      "True 6 : 299200\n",
      "Prediction 7 : 260198.66\n",
      "True 7 : 241400\n",
      "Prediction 8 : 203221.55\n",
      "True 8 : 226700\n",
      "Prediction 9 : 244312.89\n",
      "True 9 : 261100\n",
      "RMSE: 163641.9845462217\n"
     ]
    }
   ],
   "source": [
    "yhat2 = model.predict(x)\n",
    "y_pred2 = unscale(yhat2)\n",
    "y_pred2 = y_pred2.flatten()\n",
    "for i in range(10):\n",
    "    print('Prediction', i, ':', y_pred2[i])\n",
    "    print('True', i, ':', y_orig[i])\n",
    "print('RMSE:', np.sqrt(mean_squared_error(y_orig, y_pred2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ionosphere dataset models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method DataFrame.info of      0   1        2        3        4        5        6        7        8   \\\n",
      "0     1   0  0.99539 -0.05889  0.85243  0.02306  0.83398 -0.37708  1.00000   \n",
      "1     1   0  1.00000 -0.18829  0.93035 -0.36156 -0.10868 -0.93597  1.00000   \n",
      "2     1   0  1.00000 -0.03365  1.00000  0.00485  1.00000 -0.12062  0.88965   \n",
      "3     1   0  1.00000 -0.45161  1.00000  1.00000  0.71216 -1.00000  0.00000   \n",
      "4     1   0  1.00000 -0.02401  0.94140  0.06531  0.92106 -0.23255  0.77152   \n",
      "..   ..  ..      ...      ...      ...      ...      ...      ...      ...   \n",
      "346   1   0  0.83508  0.08298  0.73739 -0.14706  0.84349 -0.05567  0.90441   \n",
      "347   1   0  0.95113  0.00419  0.95183 -0.02723  0.93438 -0.01920  0.94590   \n",
      "348   1   0  0.94701 -0.00034  0.93207 -0.03227  0.95177 -0.03431  0.95584   \n",
      "349   1   0  0.90608 -0.01657  0.98122 -0.01989  0.95691 -0.03646  0.85746   \n",
      "350   1   0  0.84710  0.13533  0.73638 -0.06151  0.87873  0.08260  0.88928   \n",
      "\n",
      "          9   ...       25       26       27       28       29       30  \\\n",
      "0    0.03760  ... -0.51171  0.41078 -0.46168  0.21266 -0.34090  0.42267   \n",
      "1   -0.04549  ... -0.26569 -0.20468 -0.18401 -0.19040 -0.11593 -0.16626   \n",
      "2    0.01198  ... -0.40220  0.58984 -0.22145  0.43100 -0.17365  0.60436   \n",
      "3    0.00000  ...  0.90695  0.51613  1.00000  1.00000 -0.20099  0.25682   \n",
      "4   -0.16399  ... -0.65158  0.13290 -0.53206  0.02431 -0.62197 -0.05707   \n",
      "..       ...  ...      ...      ...      ...      ...      ...      ...   \n",
      "346 -0.04622  ... -0.04202  0.83479  0.00123  1.00000  0.12815  0.86660   \n",
      "347  0.01606  ...  0.01361  0.93522  0.04925  0.93159  0.08168  0.94066   \n",
      "348  0.02446  ...  0.03193  0.92489  0.02542  0.92120  0.02242  0.92459   \n",
      "349  0.00110  ... -0.02099  0.89147 -0.07760  0.82983 -0.17238  0.96022   \n",
      "350 -0.09139  ... -0.15114  0.81147 -0.04822  0.78207 -0.00703  0.75747   \n",
      "\n",
      "          31       32       33  34  \n",
      "0   -0.54487  0.18641 -0.45300   g  \n",
      "1   -0.06288 -0.13738 -0.02447   b  \n",
      "2   -0.24180  0.56045 -0.38238   g  \n",
      "3    1.00000 -0.32382  1.00000   b  \n",
      "4   -0.59573 -0.04608 -0.65697   g  \n",
      "..       ...      ...      ...  ..  \n",
      "346 -0.10714  0.90546 -0.04307   g  \n",
      "347 -0.00035  0.91483  0.04712   g  \n",
      "348  0.00442  0.92697 -0.00577   g  \n",
      "349 -0.03757  0.87403 -0.16243   g  \n",
      "350 -0.06678  0.85764 -0.06151   g  \n",
      "\n",
      "[351 rows x 35 columns]>\n",
      "Null values\n",
      "0     0\n",
      "1     0\n",
      "2     0\n",
      "3     0\n",
      "4     0\n",
      "5     0\n",
      "6     0\n",
      "7     0\n",
      "8     0\n",
      "9     0\n",
      "10    0\n",
      "11    0\n",
      "12    0\n",
      "13    0\n",
      "14    0\n",
      "15    0\n",
      "16    0\n",
      "17    0\n",
      "18    0\n",
      "19    0\n",
      "20    0\n",
      "21    0\n",
      "22    0\n",
      "23    0\n",
      "24    0\n",
      "25    0\n",
      "26    0\n",
      "27    0\n",
      "28    0\n",
      "29    0\n",
      "30    0\n",
      "31    0\n",
      "32    0\n",
      "33    0\n",
      "34    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "ion_data = pd.read_csv('ionosphere.csv', header=None)\n",
    "print(ion_data.info)\n",
    "print('Null values')\n",
    "print(ion_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "g class: 0\n",
      "b class: 1\n",
      "After ordinal encoding:\n",
      "[0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0\n",
      " 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1\n",
      " 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 0 1 0 1 0 1 0 1 0 1 0 1 0 1\n",
      " 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0\n",
      " 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1\n",
      " 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0\n",
      " 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "# One hot, label is last two columns\n",
    "def one_hot(cat, hot):\n",
    "    if cat == hot:\n",
    "        return int(1)\n",
    "    else:\n",
    "        return int(0)\n",
    "    \n",
    "ion_data[35] = ion_data[34].apply(one_hot, hot='g')\n",
    "ion_data[36] = ion_data[34].apply(one_hot, hot='b')\n",
    "\"\"\"\n",
    "\n",
    "def ordinal_encoder(category):\n",
    "    dict = {'g': 0, 'b': 1}\n",
    "    return dict[category]\n",
    "\n",
    "print('g class:', ordinal_encoder('g'))\n",
    "print('b class:', ordinal_encoder('b'))\n",
    "ion_data[34] = ion_data[34].apply(ordinal_encoder)\n",
    "print('After ordinal encoding:')\n",
    "print(ion_data[34].to_numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(351, 33)\n",
      "(351, 1)\n"
     ]
    }
   ],
   "source": [
    "# split x and y\n",
    "x = ion_data.iloc[:,0:33].to_numpy()\n",
    "y = ion_data.iloc[:,34].to_numpy().reshape(-1,1)\n",
    "\n",
    "# Scaling\n",
    "scaler = StandardScaler()\n",
    "x = scaler.fit_transform(x)\n",
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span>3.</span>Using Pytorch or Tensoflow, perform MLE for a neural network Bernoulli prediction model for the\n",
    "ionosphere dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"IonosphereNNMLE\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 33)]              0         \n",
      "_________________________________________________________________\n",
      "hidden1 (Dense)              (None, 5)                 170       \n",
      "_________________________________________________________________\n",
      "out (Dense)                  (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 176\n",
      "Trainable params: 176\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "input3 = tf.keras.layers.Input(33)\n",
    "h1 = tf.keras.layers.Dense(5, activation=tf.keras.activations.relu, name=\"hidden1\")(input3)\n",
    "out3 = tf.keras.layers.Dense(1, activation=tf.keras.activations.sigmoid, name=\"out\")(h1)\n",
    "\n",
    "model3 = tf.keras.Model(inputs=input3, outputs=out3, name=\"IonosphereNNMLE\")\n",
    "\n",
    "model3.compile(optimizer=tf.optimizers.Adam(learning_rate=0.01), loss=tf.losses.binary_crossentropy, metrics=[tf.keras.metrics.BinaryAccuracy(threshold=0.5)])\n",
    "print(model3.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.5941 - binary_accuracy: 0.7123\n",
      "Epoch 2/30\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.4802 - binary_accuracy: 0.8205\n",
      "Epoch 3/30\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.4117 - binary_accuracy: 0.8519\n",
      "Epoch 4/30\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3509 - binary_accuracy: 0.8689\n",
      "Epoch 5/30\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3108 - binary_accuracy: 0.8917\n",
      "Epoch 6/30\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.2762 - binary_accuracy: 0.9003\n",
      "Epoch 7/30\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.2578 - binary_accuracy: 0.9031\n",
      "Epoch 8/30\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.2399 - binary_accuracy: 0.9117\n",
      "Epoch 9/30\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.2253 - binary_accuracy: 0.9174\n",
      "Epoch 10/30\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.2121 - binary_accuracy: 0.9259\n",
      "Epoch 11/30\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.2000 - binary_accuracy: 0.9288\n",
      "Epoch 12/30\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.1896 - binary_accuracy: 0.9402\n",
      "Epoch 13/30\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.1813 - binary_accuracy: 0.9430\n",
      "Epoch 14/30\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.1732 - binary_accuracy: 0.9459\n",
      "Epoch 15/30\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.1655 - binary_accuracy: 0.9487\n",
      "Epoch 16/30\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.1591 - binary_accuracy: 0.9459\n",
      "Epoch 17/30\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.1514 - binary_accuracy: 0.9516\n",
      "Epoch 18/30\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.1501 - binary_accuracy: 0.9487\n",
      "Epoch 19/30\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.1446 - binary_accuracy: 0.9544\n",
      "Epoch 20/30\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.1374 - binary_accuracy: 0.9544\n",
      "Epoch 21/30\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.1337 - binary_accuracy: 0.9516\n",
      "Epoch 22/30\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.1290 - binary_accuracy: 0.9601\n",
      "Epoch 23/30\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.1278 - binary_accuracy: 0.9573\n",
      "Epoch 24/30\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.1227 - binary_accuracy: 0.9658\n",
      "Epoch 25/30\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.1173 - binary_accuracy: 0.9658\n",
      "Epoch 26/30\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.1152 - binary_accuracy: 0.9687\n",
      "Epoch 27/30\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.1117 - binary_accuracy: 0.9715\n",
      "Epoch 28/30\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.1079 - binary_accuracy: 0.9658\n",
      "Epoch 29/30\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.1037 - binary_accuracy: 0.9772\n",
      "Epoch 30/30\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.1002 - binary_accuracy: 0.9772\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa75c4681c0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.fit(x, y, epochs=30, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98       225\n",
      "           1       0.96      0.96      0.96       126\n",
      "\n",
      "    accuracy                           0.97       351\n",
      "   macro avg       0.97      0.97      0.97       351\n",
      "weighted avg       0.97      0.97      0.97       351\n",
      "\n"
     ]
    }
   ],
   "source": [
    "yhat = model3.predict(x)\n",
    "def labelmaker(prob):\n",
    "    if prob > 0.4:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "yhat = np.apply_along_axis(labelmaker, 1, yhat)\n",
    "print(classification_report(y.flatten(), yhat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span>4.</span>Using Pytorch or Tensoflow, perform Maximum a Posterori (MAP) estimation for a neural network\n",
    "Bernoulli prediction model and a mean zero Gaussian parameter prior for the ionosphere dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"IonosphereNNMAP\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 33)]              0         \n",
      "_________________________________________________________________\n",
      "hidden1 (Dense)              (None, 5)                 170       \n",
      "_________________________________________________________________\n",
      "L2Regularization (Dense)     (None, 5)                 30        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 6         \n",
      "=================================================================\n",
      "Total params: 206\n",
      "Trainable params: 206\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "input4 = tf.keras.layers.Input(33)\n",
    "h1 = tf.keras.layers.Dense(5, activation=tf.keras.activations.relu, name=\"hidden1\")(input4)\n",
    "reg4 = tf.keras.layers.Dense(5, kernel_regularizer=tf.keras.regularizers.L2(l2=0.05), name=\"L2Regularization\")(h1)\n",
    "out4 = tf.keras.layers.Dense(1, activation=tf.keras.activations.sigmoid)(reg4)\n",
    "\n",
    "model4 = tf.keras.Model(inputs=input4, outputs=out4, name=\"IonosphereNNMAP\")\n",
    "\n",
    "model4.compile(optimizer=tf.optimizers.Adam(learning_rate=0.001), loss=tf.losses.BinaryCrossentropy())\n",
    "print(model4.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.9757\n",
      "Epoch 2/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.9328\n",
      "Epoch 3/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.8974\n",
      "Epoch 4/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.8651\n",
      "Epoch 5/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.8366\n",
      "Epoch 6/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.8093\n",
      "Epoch 7/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.7840\n",
      "Epoch 8/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.7589\n",
      "Epoch 9/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.7344\n",
      "Epoch 10/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.7110\n",
      "Epoch 11/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.6900\n",
      "Epoch 12/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.6698\n",
      "Epoch 13/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.6510\n",
      "Epoch 14/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.6338\n",
      "Epoch 15/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.6173\n",
      "Epoch 16/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.6019\n",
      "Epoch 17/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.5868\n",
      "Epoch 18/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.5725\n",
      "Epoch 19/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.5586\n",
      "Epoch 20/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.5456\n",
      "Epoch 21/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.5328\n",
      "Epoch 22/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.5210\n",
      "Epoch 23/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.5093\n",
      "Epoch 24/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.4979\n",
      "Epoch 25/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.4871\n",
      "Epoch 26/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.4767\n",
      "Epoch 27/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.4670\n",
      "Epoch 28/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.4573\n",
      "Epoch 29/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.4482\n",
      "Epoch 30/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.4395\n",
      "Epoch 31/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.4303\n",
      "Epoch 32/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.4222\n",
      "Epoch 33/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.4142\n",
      "Epoch 34/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.4068\n",
      "Epoch 35/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3996\n",
      "Epoch 36/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3922\n",
      "Epoch 37/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3852\n",
      "Epoch 38/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3785\n",
      "Epoch 39/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3726\n",
      "Epoch 40/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3657\n",
      "Epoch 41/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3597\n",
      "Epoch 42/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3537\n",
      "Epoch 43/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3477\n",
      "Epoch 44/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 0.3422\n",
      "Epoch 45/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3366\n",
      "Epoch 46/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3316\n",
      "Epoch 47/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3263\n",
      "Epoch 48/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3212\n",
      "Epoch 49/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3162\n",
      "Epoch 50/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 0.3114\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa71479a640>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4.fit(x, y, epochs=50, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.94       225\n",
      "           1       0.90      0.88      0.89       126\n",
      "\n",
      "    accuracy                           0.92       351\n",
      "   macro avg       0.91      0.91      0.91       351\n",
      "weighted avg       0.92      0.92      0.92       351\n",
      "\n"
     ]
    }
   ],
   "source": [
    "yhat = model4.predict(x)\n",
    "def labelmaker(prob):\n",
    "    if prob > 0.4:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "yhat = np.apply_along_axis(labelmaker, 1, yhat)\n",
    "print(classification_report(y.flatten(), yhat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test with Bernoullli distribution object instead of BCE loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"IonosphereNNMLEwDistr\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_18 (InputLayer)        [(None, 33)]              0         \n",
      "_________________________________________________________________\n",
      "hidden1 (Dense)              (None, 10)                340       \n",
      "_________________________________________________________________\n",
      "hidden2 (Dense)              (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "hidden3 (Dense)              (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "p_val (Dense)                (None, 1)                 11        \n",
      "_________________________________________________________________\n",
      "output (DistributionLambda)  multiple                  0         \n",
      "=================================================================\n",
      "Total params: 571\n",
      "Trainable params: 571\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "input31 = tf.keras.layers.Input(33)\n",
    "h31 = tf.keras.layers.Dense(10, activation=tf.keras.activations.relu, name=\"hidden1\")(input31)\n",
    "h32 = tf.keras.layers.Dense(10, activation=tf.keras.activations.relu, name=\"hidden2\")(h31)\n",
    "h33 = tf.keras.layers.Dense(10, activation=tf.keras.activations.relu, name=\"hidden3\")(h32)\n",
    "p_val = tf.keras.layers.Dense(1, activation=tf.keras.activations.sigmoid, name=\"p_val\")(h33)\n",
    "out31 = tfp.layers.DistributionLambda(lambda t: tfp.distributions.Bernoulli(probs=t,  dtype=tf.float64), name=\"output\")(p_val)\n",
    "\n",
    "model31 = tf.keras.Model(inputs=input31, outputs=out31, name=\"IonosphereNNMLEwDistr\")\n",
    "\n",
    "model31.compile(optimizer=tf.optimizers.Adam(learning_rate=0.001), loss=expectNLL)\n",
    "print(model31.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 3.2111e-05\n",
      "Epoch 2/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 3.1104e-05\n",
      "Epoch 3/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 3.0065e-05\n",
      "Epoch 4/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 2.9196e-05\n",
      "Epoch 5/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 2.8392e-05\n",
      "Epoch 6/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 2.7695e-05\n",
      "Epoch 7/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 2.7080e-05\n",
      "Epoch 8/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 2.6449e-05\n",
      "Epoch 9/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 2.5879e-05\n",
      "Epoch 10/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 2.5266e-05\n",
      "Epoch 11/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2.4646e-05\n",
      "Epoch 12/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2.4036e-05\n",
      "Epoch 13/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 2.3423e-05\n",
      "Epoch 14/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 2.2822e-05\n",
      "Epoch 15/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 2.2183e-05\n",
      "Epoch 16/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 2.1483e-05\n",
      "Epoch 17/50\n",
      "11/11 [==============================] - 0s 2ms/step - loss: 2.0737e-05\n",
      "Epoch 18/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1.9968e-05\n",
      "Epoch 19/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1.9206e-05\n",
      "Epoch 20/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1.8426e-05\n",
      "Epoch 21/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1.7524e-05\n",
      "Epoch 22/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1.6724e-05\n",
      "Epoch 23/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1.5898e-05\n",
      "Epoch 24/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1.5162e-05\n",
      "Epoch 25/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1.4457e-05\n",
      "Epoch 26/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1.3783e-05\n",
      "Epoch 27/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1.3139e-05\n",
      "Epoch 28/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1.2583e-05\n",
      "Epoch 29/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1.2035e-05\n",
      "Epoch 30/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1.1517e-05\n",
      "Epoch 31/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1.1052e-05\n",
      "Epoch 32/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1.0634e-05\n",
      "Epoch 33/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 1.0219e-05\n",
      "Epoch 34/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 9.8126e-06\n",
      "Epoch 35/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 9.4482e-06\n",
      "Epoch 36/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 9.1190e-06\n",
      "Epoch 37/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 8.8054e-06\n",
      "Epoch 38/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 8.4964e-06\n",
      "Epoch 39/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 8.2108e-06\n",
      "Epoch 40/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 7.9599e-06\n",
      "Epoch 41/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 7.7132e-06\n",
      "Epoch 42/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 7.4636e-06\n",
      "Epoch 43/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 7.2298e-06\n",
      "Epoch 44/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 7.0178e-06\n",
      "Epoch 45/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 6.7987e-06\n",
      "Epoch 46/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 6.6171e-06\n",
      "Epoch 47/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 6.4125e-06\n",
      "Epoch 48/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 6.1889e-06\n",
      "Epoch 49/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 6.0111e-06\n",
      "Epoch 50/50\n",
      "11/11 [==============================] - 0s 1ms/step - loss: 5.8308e-06\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa6b84e0250>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model31.fit(x, y, epochs=50, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94       225\n",
      "           1       0.91      0.87      0.89       126\n",
      "\n",
      "    accuracy                           0.92       351\n",
      "   macro avg       0.92      0.91      0.91       351\n",
      "weighted avg       0.92      0.92      0.92       351\n",
      "\n"
     ]
    }
   ],
   "source": [
    "yhat = model31.predict(x)\n",
    "yhat = np.apply_along_axis(labelmaker, 1, yhat)\n",
    "print(classification_report(y.flatten(), yhat.flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-2.6",
   "language": "python",
   "name": "tf-2.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
